import re
import logging
from datetime import datetime
from lxml import html
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import markdownify
import uvicorn

# é…ç½®æ—¥å¿—
def setup_logging():
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    # åˆ›å»ºæ—¥å¿—æ–‡ä»¶åï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_filename = f"xpath_processing_{timestamp}.log"
    
    # é…ç½®æ—¥å¿—æ ¼å¼
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_filename, encoding='utf-8'),
            logging.StreamHandler()  # ä¿ç•™æ§åˆ¶å°è¾“å‡ºï¼Œä½†åªæ˜¾ç¤ºé‡è¦ä¿¡æ¯
        ]
    )
    
    # åˆ›å»ºä¸“é—¨çš„æ–‡ä»¶æ—¥å¿—å™¨ï¼ˆä¸è¾“å‡ºåˆ°æ§åˆ¶å°ï¼‰
    file_logger = logging.getLogger('file_only')
    file_logger.setLevel(logging.INFO)
    file_handler = logging.FileHandler(log_filename, encoding='utf-8')
    file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
    file_logger.addHandler(file_handler)
    file_logger.propagate = False  # é˜²æ­¢ä¼ æ’­åˆ°æ ¹æ—¥å¿—å™¨
    
    print(f"æ—¥å¿—å°†å†™å…¥æ–‡ä»¶: {log_filename}")
    return file_logger

# åˆå§‹åŒ–æ—¥å¿—
logger = setup_logging()

# FastAPIåº”ç”¨
app = FastAPI(
    title="HTML to Markdown Content Extractor",
    description="Extract main content from HTML and convert to Markdown",
    version="2.0.0"
)

# Pydanticæ¨¡å‹
class HTMLInput(BaseModel):
    html_content: str
    
class MarkdownOutput(BaseModel):
    markdown_content: str
    xpath: str
    status: str

# ç§»é™¤äº†æµè§ˆå™¨ç›¸å…³çš„å‡½æ•°ï¼Œç°åœ¨åªå¤„ç†HTMLå†…å®¹
def remove_header_footer_by_content_traceback(body):
    
    # é¦–éƒ¨å†…å®¹ç‰¹å¾å…³é”®è¯
    header_content_keywords = [
        'ç™»å½•', 'æ³¨å†Œ', 'é¦–é¡µ', 'ä¸»é¡µ', 'æ— éšœç¢', 'æ”¿åŠ¡', 'åŠäº‹', 'äº’åŠ¨', 
        'èµ°è¿›', 'ç§»åŠ¨ç‰ˆ', 'æ‰‹æœºç‰ˆ', 'å¯¼èˆª', 'èœå•', 'æœç´¢', 'å¸‚æ”¿åºœ',
        'login', 'register', 'home', 'menu', 'search', 'nav'
    ]
    
    # å°¾éƒ¨å†…å®¹ç‰¹å¾å…³é”®è¯
    footer_content_keywords = [
        'ç½‘ç«™è¯´æ˜', 'ç½‘ç«™æ ‡è¯†ç ', 'ç‰ˆæƒæ‰€æœ‰', 'ä¸»åŠå•ä½', 'æ‰¿åŠå•ä½', 
        'æŠ€æœ¯æ”¯æŒ', 'è”ç³»æˆ‘ä»¬', 'ç½‘ç«™åœ°å›¾', 'éšç§æ”¿ç­–', 'å…è´£å£°æ˜',
        'å¤‡æ¡ˆå·', 'icp', 'å…¬å®‰å¤‡æ¡ˆ', 'æ”¿åºœç½‘ç«™', 'ç½‘ç«™ç®¡ç†',
        'copyright', 'all rights reserved', 'powered by', 'designed by'
    ]
    
    # æŸ¥æ‰¾åŒ…å«é¦–éƒ¨ç‰¹å¾æ–‡å­—çš„å…ƒç´ 
    header_elements = []
    for keyword in header_content_keywords:
        xpath = f"//*[contains(text(), '{keyword}')]"
        elements = body.xpath(xpath)
        header_elements.extend(elements)
    
    # æŸ¥æ‰¾åŒ…å«å°¾éƒ¨ç‰¹å¾æ–‡å­—çš„å…ƒç´ 
    footer_elements = []
    for keyword in footer_content_keywords:
        xpath = f"//*[contains(text(), '{keyword}')]"
        elements = body.xpath(xpath)
        footer_elements.extend(elements)
    
    # æ”¶é›†éœ€è¦åˆ é™¤çš„å®¹å™¨
    containers_to_remove = set()
    
    # å¤„ç†é¦–éƒ¨å…ƒç´ 
    for element in header_elements:
        container = find_header_footer_container(element)
        if container and container not in containers_to_remove:
            containers_to_remove.add(container)
            logger.info(f"å‘ç°é¦–éƒ¨å®¹å™¨: {container.tag} class='{container.get('class', '')[:50]}'")
    
    # å¤„ç†å°¾éƒ¨å…ƒç´ 
    for element in footer_elements:
        container = find_footer_container_by_traceback(element)
        if container and container not in containers_to_remove:
            containers_to_remove.add(container)
            logger.info(f"å‘ç°å°¾éƒ¨å®¹å™¨: {container.tag} class='{container.get('class', '')[:50]}'")
    
    # é¢å¤–æ£€æŸ¥ï¼šæŸ¥æ‰¾æ‰€æœ‰ç›´æ¥åŒ…å«header/footeræ ‡ç­¾çš„divå®¹å™¨
    header_divs = body.xpath(".//div[.//header] | .//div[.//footer] | .//div[.//nav]")
    for div in header_divs:
        # æ£€æŸ¥è¿™ä¸ªdivæ˜¯å¦åŒ…å«é¦–éƒ¨/å°¾éƒ¨å†…å®¹ç‰¹å¾
        div_text = div.text_content().lower()
        
        header_count = sum(1 for keyword in header_content_keywords if keyword in div_text)
        footer_count = sum(1 for keyword in footer_content_keywords if keyword in div_text)
        
        if header_count >= 2 or footer_count >= 2:
            if div not in containers_to_remove:
                containers_to_remove.add(div)    
    # åˆ é™¤å®¹å™¨
    removed_count = 0
    for container in containers_to_remove:
        try:
            parent = container.getparent()
            if parent is not None:
                parent.remove(container)
                removed_count += 1
        except Exception as e:
            logger.error(f"åˆ é™¤å®¹å™¨æ—¶å‡ºé”™: {e}")
    
    return body

def find_header_footer_container(element):
    """é€šè¿‡å›æº¯æ‰¾åˆ°åŒ…å«é¦–éƒ¨/å°¾éƒ¨ç‰¹å¾çš„å®¹å™¨ - å¢å¼ºç‰ˆ"""
    current = element
    
    # å‘ä¸Šå›æº¯æŸ¥æ‰¾å®¹å™¨
    while current is not None and current.tag != 'html':
        # æ£€æŸ¥å½“å‰å…ƒç´ æ˜¯å¦ä¸ºå®¹å™¨ï¼ˆdivã€sectionã€headerã€footerã€navç­‰ï¼‰
        if current.tag in ['div', 'section', 'header', 'footer', 'nav', 'aside']:
            # æ£€æŸ¥å®¹å™¨æ˜¯å¦åŒ…å«é¦–éƒ¨/å°¾éƒ¨ç»“æ„ç‰¹å¾
            classes = current.get('class', '').lower()
            elem_id = current.get('id', '').lower()
            tag_name = current.tag.lower()
            
            # é¦–éƒ¨ç»“æ„ç‰¹å¾
            header_indicators = ['header', 'nav', 'navigation', 'menu', 'topbar', 'banner', 'menubar', 'head']
            # å°¾éƒ¨ç»“æ„ç‰¹å¾
            footer_indicators = ['footer', 'foot', 'bottom', 'end', 'copyright', 'links', 'sitemap', 'contact']
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«é¦–éƒ¨æˆ–å°¾éƒ¨ç»“æ„ç‰¹å¾
            for indicator in header_indicators + footer_indicators:
                if (indicator in classes or indicator in elem_id or indicator in tag_name):
                    return current
        
        # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾é¡¶å±‚æ ‡ç­¾
        parent = current.getparent()
        if parent is None or parent.tag in ['html', 'head', 'body', 'script', 'meta']:
            # å¦‚æœçˆ¶çº§æ˜¯htmlæˆ–bodyï¼Œè¯´æ˜å·²ç»åˆ°é¡¶äº†
            break
        
        # ç»§ç»­å‘ä¸ŠæŸ¥æ‰¾
        current = parent
    
    # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœå½“å‰å…ƒç´ è¢«divåŒ…è£…ï¼Œä½†divæœ¬èº«æ²¡æœ‰æ˜æ˜¾ç‰¹å¾
    # æ£€æŸ¥å½“å‰å…ƒç´ çš„çˆ¶çº§æ˜¯å¦æ˜¯divï¼Œä¸”ç¥–çˆ¶çº§æ˜¯body/html
    if (element.getparent() and 
        element.getparent().tag == 'div' and 
        element.getparent().getparent() and 
        element.getparent().getparent().tag in ['body', 'html']):
        
        # æ£€æŸ¥è¿™ä¸ªdivæ˜¯å¦åŒ…å«é¦–éƒ¨/å°¾éƒ¨å†…å®¹ç‰¹å¾
        div_element = element.getparent()
        div_text = div_element.text_content().lower()
        
        # é¦–éƒ¨å†…å®¹ç‰¹å¾å…³é”®è¯
        header_content_keywords = [
            'ç™»å½•', 'æ³¨å†Œ', 'é¦–é¡µ', 'ä¸»é¡µ', 'æ— éšœç¢', 'æ”¿åŠ¡', 'åŠäº‹', 'äº’åŠ¨', 
            'èµ°è¿›', 'ç§»åŠ¨ç‰ˆ', 'æ‰‹æœºç‰ˆ', 'å¯¼èˆª', 'èœå•', 'æœç´¢', 'å¸‚æ”¿åºœ'
        ]
        
        # å°¾éƒ¨å†…å®¹ç‰¹å¾å…³é”®è¯
        footer_content_keywords = [
            'ç½‘ç«™è¯´æ˜', 'ç½‘ç«™æ ‡è¯†ç ', 'ç‰ˆæƒæ‰€æœ‰', 'ä¸»åŠå•ä½', 'æ‰¿åŠå•ä½', 
            'æŠ€æœ¯æ”¯æŒ', 'è”ç³»æˆ‘ä»¬', 'ç½‘ç«™åœ°å›¾', 'éšç§æ”¿ç­–', 'å…è´£å£°æ˜',
            'å¤‡æ¡ˆå·', 'icp', 'å…¬å®‰å¤‡æ¡ˆ', 'æ”¿åºœç½‘ç«™', 'ç½‘ç«™ç®¡ç†'
        ]
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤šä¸ªé¦–éƒ¨æˆ–å°¾éƒ¨å…³é”®è¯
        header_count = sum(1 for keyword in header_content_keywords if keyword in div_text)
        footer_count = sum(1 for keyword in footer_content_keywords if keyword in div_text)
        
        if header_count >= 2 or footer_count >= 2:
            return div_element
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜æ˜¾çš„ç»“æ„ç‰¹å¾å®¹å™¨ï¼Œè¿”å›ç›´æ¥çˆ¶çº§å®¹å™¨
    if element.getparent() and element.getparent().tag != 'html':
        return element.getparent()
    
    return None
def find_footer_container_by_traceback(element):
    """é€šè¿‡å›æº¯æ‰¾åˆ°footerå®¹å™¨"""
    current = element
    
    while current is not None:
        # æ£€æŸ¥å½“å‰å…ƒç´ æ˜¯å¦ä¸ºå®¹å™¨
        if current.tag in ['div', 'section', 'footer']:
            # æ£€æŸ¥å®¹å™¨ç‰¹å¾
            classes = current.get('class', '').lower()
            elem_id = current.get('id', '').lower()
            
            # footerç»“æ„ç‰¹å¾
            footer_indicators = ['footer', 'foot', 'bottom', 'end', 'copyright']
            for indicator in footer_indicators:
                if indicator in classes or indicator in elem_id:
                    return current
        
        # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾é¡¶å±‚æ ‡ç­¾
        parent = current.getparent()
        if parent is None or parent.tag in ['html', 'head', 'body', 'script', 'meta']:
            break
            
        current = parent
    
    return None
def preprocess_html_remove_interference(page_tree):
    """
    ç²¾å‡†æ¸…ç†HTML - åªæ¿€è¿›åˆ é™¤é¡µé¢çº§headerå’Œfooterï¼Œä¿æŠ¤å†…å®¹åŒºåŸŸ
    """
    # è·å–bodyå…ƒç´ 
    body = page_tree.xpath("//body")[0] if page_tree.xpath("//body") else page_tree
    
    logger.info("å¼€å§‹ç²¾å‡†HTMLæ¸…ç†æµç¨‹...")
    
    # ç¬¬ä¸€æ­¥ï¼šæ¿€è¿›åˆ é™¤æ˜ç¡®çš„é¡µé¢çº§headerå’Œfooter
    removed_count = remove_page_level_header_footer(body)
    
    logger.info(f"ç²¾å‡†æ¸…ç†å®Œæˆï¼šåˆ é™¤äº† {removed_count} ä¸ªé¡µé¢çº§header/footer")
    
    # è¾“å‡ºæ¸…ç†åçš„HTMLåˆ°æ—¥å¿—æ–‡ä»¶
    cleaned_html = html.tostring(body, encoding='unicode', pretty_print=True)
    logger.info("\n=== æ¸…ç†åçš„HTMLå†…å®¹ ===")
    logger.info(cleaned_html[:2000] + "..." if len(cleaned_html) > 2000 else cleaned_html)
    logger.info("=== HTMLå†…å®¹ç»“æŸ ===\n")
    
    return body

def remove_page_level_header_footer(body):
    """
    æ¿€è¿›åˆ é™¤é¡µé¢çº§çš„headerå’Œfooter - åŸºäºå¤šé‡ç‰¹å¾åˆ¤æ–­
    """
    logger.info("æ‰§è¡Œæ¿€è¿›åˆ é™¤é¡µé¢çº§headerå’Œfooter...")
    
    removed_count = 0
    
    # ç¬¬ä¸€è½®ï¼šåˆ é™¤æ˜ç¡®çš„è¯­ä¹‰æ ‡ç­¾
    semantic_tags = ["//header", "//footer", "//nav"]
    for tag_xpath in semantic_tags:
        elements = body.xpath(tag_xpath)
        for element in elements:
            try:
                parent = element.getparent()
                if parent is not None:
                    parent.remove(element)
                    removed_count += 1
                    logger.info(f"  åˆ é™¤è¯­ä¹‰æ ‡ç­¾: {element.tag}")
            except Exception as e:
                logger.info(f"åˆ é™¤è¯­ä¹‰æ ‡ç­¾æ—¶å‡ºé”™: {e}")
    
    # ç¬¬äºŒè½®ï¼šåˆ é™¤å…·æœ‰å¼ºheader/footerç‰¹å¾çš„é¡¶çº§divå®¹å™¨
    top_divs = body.xpath("./div")  # åªæ£€æŸ¥bodyçš„ç›´æ¥å­div
    
    containers_to_remove = []
    
    for div in top_divs:
        classes = div.get('class', '').lower()
        elem_id = div.get('id', '').lower()
        text_content = div.text_content().lower()
        
        is_header_footer = False
        
        # å¼ºheaderç‰¹å¾
        strong_header_indicators = [
            'header', 'top', 'navbar', 'navigation', 'menu-main', 
            'site-header', 'page-header', 'banner', 'topbar'
        ]
        
        # å¼ºfooterç‰¹å¾
        strong_footer_indicators = [
            'footer', 'bottom', 'site-footer', 'page-footer', 
            'footerpc', 'wapfooter', 'g-bottom'
        ]
        
        # æ£€æŸ¥ç±»åå’ŒIDä¸­çš„å¼ºç‰¹å¾
        for indicator in strong_header_indicators + strong_footer_indicators:
            if indicator in classes or indicator in elem_id:
                is_header_footer = True
                logger.info(f"  å‘ç°å¼ºç»“æ„ç‰¹å¾: {indicator} in class/id")
                break
        
        # åŸºäºå†…å®¹çš„å¼ºç‰¹å¾åˆ¤æ–­ï¼ˆæ›´ä¸¥æ ¼çš„æ¡ä»¶ï¼‰
        if not is_header_footer:
            # Headerå†…å®¹ç‰¹å¾ï¼ˆéœ€è¦å¤šä¸ªæ¡ä»¶åŒæ—¶æ»¡è¶³ï¼‰
            header_words = [
                'ç™»å½•', 'æ³¨å†Œ', 'é¦–é¡µ', 'ä¸»é¡µ', 'æ— éšœç¢', 'æ”¿åŠ¡', 'åŠäº‹', 'äº’åŠ¨', 
                'èµ°è¿›', 'ç§»åŠ¨ç‰ˆ', 'æ‰‹æœºç‰ˆ', 'å¯¼èˆª', 'èœå•', 'æœç´¢', 'å¸‚æ”¿åºœ',
                'login', 'register', 'home', 'menu', 'search', 'nav'
            ]
            header_count = sum(1 for word in header_words if word in text_content)
            
            # Footerå†…å®¹ç‰¹å¾ï¼ˆéœ€è¦å¤šä¸ªæ¡ä»¶åŒæ—¶æ»¡è¶³ï¼‰
            footer_words =  [
                'ç½‘ç«™è¯´æ˜', 'ç½‘ç«™æ ‡è¯†ç ', 'ç‰ˆæƒæ‰€æœ‰', 'ä¸»åŠå•ä½', 'æ‰¿åŠå•ä½', 
                'æŠ€æœ¯æ”¯æŒ', 'è”ç³»æˆ‘ä»¬', 'ç½‘ç«™åœ°å›¾', 'éšç§æ”¿ç­–', 'å…è´£å£°æ˜',
                'å¤‡æ¡ˆå·', 'icp', 'å…¬å®‰å¤‡æ¡ˆ', 'æ”¿åºœç½‘ç«™', 'ç½‘ç«™ç®¡ç†',
                'copyright', 'all rights reserved', 'powered by', 'designed by'
            ]
            footer_count = sum(1 for word in footer_words if word in text_content)
            
            text_length = len(text_content.strip())
            
            # åªæœ‰å½“ç‰¹å¾è¯æ±‡éå¸¸é›†ä¸­ä¸”å®¹å™¨ç›¸å¯¹è¾ƒå°æ—¶æ‰åˆ é™¤
            if header_count >= 4 and text_length < 1000:
                is_header_footer = True
                logger.info(f"  å‘ç°å¼ºheaderå†…å®¹ç‰¹å¾: {header_count}ä¸ªå…³é”®è¯")
            elif footer_count >= 3 and text_length < 800:
                is_header_footer = True
                logger.info(f"  å‘ç°å¼ºfooterå†…å®¹ç‰¹å¾: {footer_count}ä¸ªå…³é”®è¯")
        
        if is_header_footer:
            containers_to_remove.append(div)
    
    # åˆ é™¤æ ‡è®°çš„å®¹å™¨
    for container in containers_to_remove:
        try:
            parent = container.getparent()
            if parent is not None:
                parent.remove(container)
                removed_count += 1
                logger.info(f"  åˆ é™¤é¡µé¢çº§å®¹å™¨: {container.tag} class='{container.get('class', '')[:30]}'")
        except Exception as e:
            logger.error(f"åˆ é™¤é¡µé¢çº§å®¹å™¨æ—¶å‡ºé”™: {e}")
    
    return removed_count

def calculate_text_density(element):
    """
    è®¡ç®—å…ƒç´ çš„æ–‡æœ¬å¯†åº¦ - å€Ÿé‰´trafilaturaçš„å¯†åº¦è®¡ç®—
    å¯†åº¦ = æ–‡æœ¬é•¿åº¦ / (æ ‡ç­¾æ•°é‡ + é“¾æ¥æ•°é‡ * æƒé‡)
    """
    text_content = element.text_content().strip()
    text_length = len(text_content)
    
    if text_length == 0:
        return 0
    
    # è®¡ç®—æ ‡ç­¾æ•°é‡
    all_tags = element.xpath(".//*")
    tag_count = len(all_tags)
    
    # è®¡ç®—é“¾æ¥æ•°é‡ï¼ˆé“¾æ¥é€šå¸¸åœ¨å¯¼èˆªä¸­å¯†é›†å‡ºç°ï¼‰
    links = element.xpath(".//a")
    link_count = len(links)
    
    # è®¡ç®—å›¾ç‰‡æ•°é‡
    images = element.xpath(".//img")
    image_count = len(images)
    
    # å¯†åº¦è®¡ç®—ï¼šæ–‡æœ¬è¶Šå¤šã€æ ‡ç­¾è¶Šå°‘ã€é“¾æ¥è¶Šå°‘ = å¯†åº¦è¶Šé«˜
    # é“¾æ¥å¯†é›†çš„åŒºåŸŸï¼ˆå¦‚å¯¼èˆªï¼‰ä¼šæœ‰è¾ƒä½å¯†åº¦
    denominator = max(1, tag_count + link_count * 2 + image_count * 0.5)
    density = text_length / denominator
    
    return density

def remove_low_density_containers(body):
    """
    ç¬¬ä¸€æ­¥ï¼šç§»é™¤ä½å¯†åº¦å®¹å™¨ - ä¸»è¦é’ˆå¯¹å¯¼èˆªã€èœå•ç­‰é“¾æ¥å¯†é›†åŒºåŸŸ
    ä½†è¦ä¿æŠ¤åŒ…å«å®é™…å†…å®¹çš„å®¹å™¨
    """
    logger.info("æ‰§è¡Œç¬¬ä¸€æ­¥ï¼šç§»é™¤ä½å¯†åº¦å®¹å™¨...")
    
    # è·å–æ‰€æœ‰é¡¶çº§å®¹å™¨ï¼ˆbodyçš„ç›´æ¥å­å…ƒç´ ï¼‰
    top_level_containers = body.xpath("./div | ./section | ./main | ./article | ./header | ./footer | ./nav | ./aside")
    
    containers_to_remove = []
    
    for container in top_level_containers:
        density = calculate_text_density(container)
        text_length = len(container.text_content().strip())
        links = container.xpath(".//a")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«é‡è¦å†…å®¹æ ‡è¯†ç¬¦ - ä¿æŠ¤è¿™äº›å®¹å™¨
        classes = container.get('class', '').lower()
        elem_id = container.get('id', '').lower()
        
        # é‡è¦å†…å®¹æ ‡è¯†ç¬¦ - è¿™äº›å®¹å™¨é€šå¸¸åŒ…å«ä¸»è¦å†…å®¹
        important_indicators = [
            'content', 'main', 'article', 'detail', 'news', 'info',
            'bg-fff', 'bg-white', 'wrapper', 'body'  # æ·»åŠ å¸¸è§çš„å†…å®¹å®¹å™¨ç±»å
        ]
        
        has_important_content = any(indicator in classes or indicator in elem_id 
                                  for indicator in important_indicators)
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ–‡ç« ç‰¹å¾ï¼ˆæ—¶é—´ã€æ ‡é¢˜ç­‰ï¼‰
        has_article_features = bool(
            container.xpath(".//h1 | .//h2 | .//h3") or  # æ ‡é¢˜
            container.xpath(".//*[contains(text(), 'å‘å¸ƒæ—¶é—´') or contains(text(), 'æ¥æº') or contains(text(), 'æµè§ˆæ¬¡æ•°')]") or  # æ–‡ç« å…ƒä¿¡æ¯
            len(container.xpath(".//p")) > 3  # å¤šä¸ªæ®µè½
        )
        
        # å¦‚æœåŒ…å«é‡è¦å†…å®¹æˆ–æ–‡ç« ç‰¹å¾ï¼Œè·³è¿‡åˆ é™¤
        if has_important_content or has_article_features:
            logger.info(f"  ä¿æŠ¤é‡è¦å†…å®¹å®¹å™¨: class='{classes[:30]}' (åŒ…å«é‡è¦å†…å®¹æ ‡è¯†æˆ–æ–‡ç« ç‰¹å¾)")
            continue
        
        # ä½å¯†åº¦ä¸”é“¾æ¥å¯†é›†çš„å®¹å™¨å¾ˆå¯èƒ½æ˜¯å¯¼èˆª
        link_ratio = len(links) / max(1, len(container.xpath(".//*")))
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºä½è´¨é‡å®¹å™¨
        is_low_quality = False
        
        # æ¡ä»¶1ï¼šå¯†åº¦æä½ä¸”é“¾æ¥æ¯”ä¾‹é«˜ï¼ˆå…¸å‹å¯¼èˆªç‰¹å¾ï¼‰
        if density < 5 and link_ratio > 0.3:
            is_low_quality = True
            logger.info(f"  å‘ç°ä½å¯†åº¦é«˜é“¾æ¥å®¹å™¨: å¯†åº¦={density:.2f}, é“¾æ¥æ¯”ä¾‹={link_ratio:.2f}")
        
        # æ¡ä»¶2ï¼šæ–‡æœ¬å¾ˆå°‘ä½†æ ‡ç­¾å¾ˆå¤šï¼ˆå¯èƒ½æ˜¯å¤æ‚çš„å¯¼èˆªç»“æ„ï¼‰
        elif text_length < 200 and len(container.xpath(".//*")) > 20:
            is_low_quality = True
            logger.info(f"  å‘ç°å°‘æ–‡æœ¬å¤šæ ‡ç­¾å®¹å™¨: æ–‡æœ¬é•¿åº¦={text_length}, æ ‡ç­¾æ•°={len(container.xpath('.//*'))}")
        
        # æ¡ä»¶3ï¼šé“¾æ¥æ–‡æœ¬å æ€»æ–‡æœ¬æ¯”ä¾‹è¿‡é«˜ï¼ˆä½†æ–‡æœ¬é•¿åº¦è¦è¶³å¤Ÿå°‘ï¼Œé¿å…è¯¯åˆ å†…å®¹é¡µï¼‰
        elif links and text_length < 500:  # å¢åŠ æ–‡æœ¬é•¿åº¦é™åˆ¶
            link_text_length = sum(len(link.text_content()) for link in links)
            if text_length > 0 and link_text_length / text_length > 0.8:  # æé«˜é˜ˆå€¼
                is_low_quality = True
                logger.info(f"  å‘ç°é“¾æ¥æ–‡æœ¬å æ¯”è¿‡é«˜å®¹å™¨: é“¾æ¥æ–‡æœ¬æ¯”ä¾‹={link_text_length/text_length:.2f}")
        
        if is_low_quality:
            containers_to_remove.append(container)
    
    # åˆ é™¤ä½è´¨é‡å®¹å™¨
    removed_count = 0
    for container in containers_to_remove:
        try:
            parent = container.getparent()
            if parent is not None:
                parent.remove(container)
                removed_count += 1
        except Exception as e:
            logger.error(f"åˆ é™¤ä½å¯†åº¦å®¹å™¨æ—¶å‡ºé”™: {e}")
    
    logger.info(f"ç¬¬ä¸€æ­¥å®Œæˆï¼šç§»é™¤äº† {removed_count} ä¸ªä½å¯†åº¦å®¹å™¨")
    return body

def remove_semantic_interference_tags(body):
    """
    ç¬¬äºŒæ­¥ï¼šå¼ºåˆ¶ç§»é™¤è¯­ä¹‰å¹²æ‰°æ ‡ç­¾ - trafilaturaçš„ç»“æ„ç‰¹å¾è¯†åˆ«
    """
    logger.info("æ‰§è¡Œç¬¬äºŒæ­¥ï¼šç§»é™¤è¯­ä¹‰å¹²æ‰°æ ‡ç­¾...")
    
    # å¼ºåˆ¶ç§»é™¤çš„è¯­ä¹‰æ ‡ç­¾
    semantic_tags_to_remove = [
        "//header", "//footer", "//nav", "//aside",
        "//div[@role='navigation']", "//div[@role='banner']", "//div[@role='contentinfo']",
        "//section[@role='navigation']"
    ]
    
    removed_count = 0
    for xpath in semantic_tags_to_remove:
        elements = body.xpath(xpath)
        for element in elements:
            try:
                parent = element.getparent()
                if parent is not None:
                    parent.remove(element)
                    removed_count += 1
                    logger.info(f"  ç§»é™¤è¯­ä¹‰æ ‡ç­¾: {element.tag} {element.get('class', '')[:30]}")
            except Exception as e:
                logger.info(f"åˆ é™¤è¯­ä¹‰æ ‡ç­¾æ—¶å‡ºé”™: {e}")
    
    logger.info(f"ç¬¬äºŒæ­¥å®Œæˆï¼šç§»é™¤äº† {removed_count} ä¸ªè¯­ä¹‰å¹²æ‰°æ ‡ç­¾")
    return body

def remove_positional_interference(body):
    """
    ç¬¬å››æ­¥ï¼šåŸºäºä½ç½®çš„æœ€ç»ˆæ¸…ç† - ç§»é™¤é¡µé¢é¡¶éƒ¨å’Œåº•éƒ¨çš„å¹²æ‰°å®¹å™¨
    """
    logger.info("æ‰§è¡Œç¬¬å››æ­¥ï¼šç§»é™¤ä½ç½®å¹²æ‰°å®¹å™¨...")
    
    # è·å–bodyçš„æ‰€æœ‰ç›´æ¥å­å®¹å™¨
    direct_children = body.xpath("./div | ./section | ./main | ./article")
    
    if len(direct_children) <= 2:
        logger.info("å®¹å™¨æ•°é‡å¤ªå°‘ï¼Œè·³è¿‡ä½ç½®æ¸…ç†")
        return body
    
    containers_to_remove = []
    
    # åˆ†æç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªå®¹å™¨
    first_container = direct_children[0] if direct_children else None
    last_container = direct_children[-1] if len(direct_children) > 1 else None
    
    # æ£€æŸ¥ç¬¬ä¸€ä¸ªå®¹å™¨æ˜¯å¦ä¸ºå¤´éƒ¨å¹²æ‰°
    if first_container is not None:
        if is_positional_header(first_container):
            containers_to_remove.append(first_container)
            logger.info(f"  æ ‡è®°ç§»é™¤å¤´éƒ¨å®¹å™¨: {first_container.tag}")
    
    # æ£€æŸ¥æœ€åä¸€ä¸ªå®¹å™¨æ˜¯å¦ä¸ºå°¾éƒ¨å¹²æ‰°
    if last_container is not None and last_container != first_container:
        if is_positional_footer(last_container):
            containers_to_remove.append(last_container)
            logger.info(f"  æ ‡è®°ç§»é™¤å°¾éƒ¨å®¹å™¨: {last_container.tag}")
    
    # åˆ é™¤ä½ç½®å¹²æ‰°å®¹å™¨
    removed_count = 0
    for container in containers_to_remove:
        try:
            parent = container.getparent()
            if parent is not None:
                parent.remove(container)
                removed_count += 1
        except Exception as e:
            logger.error(f"åˆ é™¤ä½ç½®å®¹å™¨æ—¶å‡ºé”™: {e}")
    
    logger.info(f"ç¬¬å››æ­¥å®Œæˆï¼šç§»é™¤äº† {removed_count} ä¸ªä½ç½®å¹²æ‰°å®¹å™¨")
    return body

def is_positional_header(container):
    """åˆ¤æ–­å®¹å™¨æ˜¯å¦ä¸ºä½ç½®ä¸Šçš„å¤´éƒ¨å¹²æ‰°"""
    text_content = container.text_content().lower()
    
    # å¤´éƒ¨ç‰¹å¾è¯æ±‡
    header_indicators = [
        'ç™»å½•', 'æ³¨å†Œ', 'é¦–é¡µ', 'ä¸»é¡µ', 'å¯¼èˆª', 'èœå•', 'æœç´¢',
        'æ”¿åŠ¡æœåŠ¡', 'åŠäº‹æœåŠ¡', 'äº’åŠ¨äº¤æµ', 'èµ°è¿›', 'æ— éšœç¢',
        'login', 'register', 'home', 'menu', 'search', 'nav'
    ]
    
    # è®¡ç®—å¤´éƒ¨ç‰¹å¾è¯æ±‡å‡ºç°æ¬¡æ•°
    header_count = sum(1 for word in header_indicators if word in text_content)
    
    # è®¡ç®—æ–‡æœ¬å¯†åº¦
    density = calculate_text_density(container)
    
    # åˆ¤æ–­æ¡ä»¶ï¼šåŒ…å«å¤šä¸ªå¤´éƒ¨è¯æ±‡ æˆ– å¯†åº¦å¾ˆä½ä¸”åŒ…å«å¤´éƒ¨è¯æ±‡
    return header_count >= 3 or (density < 8 and header_count >= 2)

def is_positional_footer(container):
    """åˆ¤æ–­å®¹å™¨æ˜¯å¦ä¸ºä½ç½®ä¸Šçš„å°¾éƒ¨å¹²æ‰°"""
    text_content = container.text_content().lower()
    
    # å°¾éƒ¨ç‰¹å¾è¯æ±‡
    footer_indicators = [
        'ç‰ˆæƒæ‰€æœ‰', 'ä¸»åŠå•ä½', 'æ‰¿åŠå•ä½', 'æŠ€æœ¯æ”¯æŒ', 'è”ç³»æˆ‘ä»¬',
        'ç½‘ç«™åœ°å›¾', 'éšç§æ”¿ç­–', 'å…è´£å£°æ˜', 'å¤‡æ¡ˆå·', 'icp',
        'ç½‘ç«™æ ‡è¯†ç ', 'æ”¿åºœç½‘ç«™', 'ç½‘ç«™ç®¡ç†',
        'copyright', 'all rights reserved', 'powered by'
    ]
    
    # è®¡ç®—å°¾éƒ¨ç‰¹å¾è¯æ±‡å‡ºç°æ¬¡æ•°
    footer_count = sum(1 for word in footer_indicators if word in text_content)
    
    # è®¡ç®—æ–‡æœ¬å¯†åº¦
    density = calculate_text_density(container)
    
    # åˆ¤æ–­æ¡ä»¶ï¼šåŒ…å«å¤šä¸ªå°¾éƒ¨è¯æ±‡ æˆ– å¯†åº¦å¾ˆä½ä¸”åŒ…å«å°¾éƒ¨è¯æ±‡
    return footer_count >= 2 or (density < 6 and footer_count >= 1)

def is_interference_container(container):
    """
    åˆ¤æ–­æ˜¯å¦ä¸ºéœ€è¦åˆ é™¤çš„å¹²æ‰°å®¹å™¨ - èåˆtrafilaturaçš„å¤šç»´åº¦åˆ¤æ–­
    """
    classes = container.get('class', '').lower()
    elem_id = container.get('id', '').lower()
    tag_name = container.tag.lower()
    text_content = container.text_content().lower()
    
    # 1. å¼ºåˆ¶åˆ é™¤çš„è¯­ä¹‰æ ‡ç­¾ - trafilaturaçš„ç»“æ„ç‰¹å¾
    if tag_name in ['header', 'footer', 'nav', 'aside']:
        return True
    
    # 2. å¼ºåˆ¶åˆ é™¤çš„ç»“æ„ç‰¹å¾å…³é”®è¯
    strong_interference_keywords = [
        'header', 'footer', 'nav', 'navigation', 'menu', 'menubar', 
        'topbar', 'bottom', 'sidebar', 'aside', 'banner', 'breadcrumb'
    ]
    
    for keyword in strong_interference_keywords:
        if keyword in classes or keyword in elem_id:
            return True
    
    # 3. åŸºäºå†…å®¹å¯†åº¦çš„åˆ¤æ–­ - trafilaturaçš„å¯†åº¦åˆ†æ
    density = calculate_text_density(container)
    text_length = len(text_content.strip())
    
    # ä½å¯†åº¦ + çŸ­æ–‡æœ¬ = å¾ˆå¯èƒ½æ˜¯å¯¼èˆªæˆ–è£…é¥°æ€§å…ƒç´ 
    if density < 3 and text_length < 300:
        return True
    
    # 4. åŸºäºé“¾æ¥å¯†åº¦çš„åˆ¤æ–­ - trafilaturaä¼šåˆ†æé“¾æ¥åˆ†å¸ƒ
    links = container.xpath(".//a")
    if len(links) > 5:
        link_text_length = sum(len(link.text_content()) for link in links)
        if text_length > 0:
            link_ratio = link_text_length / text_length
            # é“¾æ¥æ–‡æœ¬å æ¯”è¿‡é«˜ï¼Œå¾ˆå¯èƒ½æ˜¯å¯¼èˆª
            if link_ratio > 0.7:
                return True
    
    # 5. åŸºäºå†…å®¹ç‰¹å¾çš„ç²¾ç¡®åˆ¤æ–­
    header_content_patterns = [
        'ç™»å½•', 'æ³¨å†Œ', 'é¦–é¡µ', 'ä¸»é¡µ', 'æ— éšœç¢', 'æ”¿åŠ¡æœåŠ¡', 'åŠäº‹æœåŠ¡',
        'äº’åŠ¨äº¤æµ', 'èµ°è¿›', 'ç§»åŠ¨ç‰ˆ', 'æ‰‹æœºç‰ˆ', 'å¯¼èˆª', 'èœå•', 'æœç´¢',
        'login', 'register', 'home', 'menu', 'search', 'nav'
    ]
    
    footer_content_patterns = [
        'ç½‘ç«™è¯´æ˜', 'ç½‘ç«™æ ‡è¯†ç ', 'ç‰ˆæƒæ‰€æœ‰', 'ä¸»åŠå•ä½', 'æ‰¿åŠå•ä½',
        'æŠ€æœ¯æ”¯æŒ', 'è”ç³»æˆ‘ä»¬', 'ç½‘ç«™åœ°å›¾', 'éšç§æ”¿ç­–', 'å…è´£å£°æ˜',
        'å¤‡æ¡ˆå·', 'icp', 'å…¬å®‰å¤‡æ¡ˆ', 'æ”¿åºœç½‘ç«™', 'ç½‘ç«™ç®¡ç†',
        'copyright', 'all rights reserved', 'powered by'
    ]
    
    # è®¡ç®—å†…å®¹ç‰¹å¾åŒ¹é…åº¦
    header_matches = sum(1 for pattern in header_content_patterns if pattern in text_content)
    footer_matches = sum(1 for pattern in footer_content_patterns if pattern in text_content)
    
    # é™ä½é˜ˆå€¼ï¼Œæ›´ä¸¥æ ¼åœ°è¯†åˆ«å¹²æ‰°å†…å®¹
    if header_matches >= 2:  # ä»3é™åˆ°2
        return True
    
    if footer_matches >= 2:  # ä»3é™åˆ°2
        return True
    
    # 6. åŸºäºä½ç½®å’Œå¤§å°çš„ç»¼åˆåˆ¤æ–­
    # å¾ˆå°çš„å®¹å™¨ä½†åŒ…å«å¤šä¸ªç‰¹å¾è¯æ±‡ï¼Œå¾ˆå¯èƒ½æ˜¯å¹²æ‰°
    if text_length < 200 and (header_matches + footer_matches) >= 2:
        return True
    
    # 7. ç‰¹æ®Šæƒ…å†µï¼šå¹¿å‘Šå’Œç¤¾äº¤åª’ä½“ç›¸å…³
    ad_keywords = ['advertisement', 'ads', 'social', 'share', 'follow', 'subscribe']
    ad_matches = sum(1 for keyword in ad_keywords if keyword in text_content or keyword in classes)
    if ad_matches >= 2:
        return True
    
    return False

def find_article_container(page_tree):
    cleaned_body = preprocess_html_remove_interference(page_tree)
    main_content = find_main_content_in_cleaned_html(cleaned_body)
    
    return main_content

def extract_content_to_markdown(html_content: str):
    """
    ä»HTMLå†…å®¹ä¸­æå–æ­£æ–‡å¹¶è½¬æ¢ä¸ºMarkdownæ ¼å¼
    
    Args:
        html_content: è¾“å…¥çš„HTMLå†…å®¹å­—ç¬¦ä¸²
        
    Returns:
        dict: åŒ…å«markdownå†…å®¹ã€xpathå’ŒçŠ¶æ€çš„å­—å…¸
    """
    try:
        # è§£æHTML
        tree = html.fromstring(html_content)
        
        # è·å–ä¸»å†…å®¹å®¹å™¨
        main_container = find_article_container(tree)
        
        if not main_container:
            logger.error("æœªæ‰¾åˆ°ä¸»å†…å®¹å®¹å™¨")
            return {
                'markdown_content': '',
                'xpath': '',
                'status': 'failed'
            }
        
        # ç”ŸæˆXPath
        xpath = generate_xpath(main_container)
        
        # è·å–å®¹å™¨çš„HTMLå†…å®¹
        container_html = html.tostring(main_container, encoding='unicode', pretty_print=True)
        cleaned_container_html = clean_container_html(container_html)
        # è½¬æ¢ä¸ºMarkdown
        markdown_content = markdownify.markdownify(
            cleaned_container_html,
            heading_style="ATX",  # ä½¿ç”¨ # æ ¼å¼çš„æ ‡é¢˜
            bullets="-",  # ä½¿ç”¨ - ä½œä¸ºåˆ—è¡¨ç¬¦å·
            strip=['script', 'style']  # ç¬¬äºŒæ¬¡ç§»é™¤scriptå’Œstyleæ ‡ç­¾ï¼ˆè¿™é‡Œçš„æ¸…é™¤æ•ˆæœè²Œä¼¼ä¸æ˜¯å¾ˆå¥½ï¼Œscriptæ ‡ç­¾æ²¡æœ‰æ­£ç¡®çš„å»é™¤ï¼‰
        )
        
        # æ¸…ç†Markdownå†…å®¹
        markdown_content = clean_markdown_content(markdown_content)
        
        logger.info(f"æˆåŠŸæå–å†…å®¹ï¼ŒXPath: {xpath}")
        logger.info(f"Markdownå†…å®¹é•¿åº¦: {len(markdown_content)}")
        
        return {
            'markdown_content': markdown_content,
            'xpath': xpath,
            'status': 'success'
        }
        
    except Exception as e:
        logger.error(f"æå–å†…å®¹æ—¶å‡ºé”™: {str(e)}")
        return {
            'markdown_content': '',
            'xpath': '',
            'status': 'failed'
        }
def clean_container_html(container_html: str) -> str:
    """
    æ¸…ç†htmlå†…å®¹ï¼Œåˆ é™¤scriptã€styleå’Œjsä»£ç 
    """
    from bs4 import BeautifulSoup

    # è§£æHTML
    soup = BeautifulSoup(container_html, 'html.parser')
    
    # åˆ é™¤scriptæ ‡ç­¾
    for script in soup.find_all('script'):
        script.decompose()
    
    # åˆ é™¤styleæ ‡ç­¾
    for style in soup.find_all('style'):
        style.decompose()
    
    # åˆ é™¤åŒ…å«JavaScriptçš„å±æ€§
    for tag in soup.find_all():
        # åˆ é™¤onclickã€onloadç­‰äº‹ä»¶å±æ€§
        attrs_to_remove = []
        for attr in tag.attrs:
            if attr.startswith('on'):  # onclick, onload, onmouseoverç­‰
                attrs_to_remove.append(attr)
        
        for attr in attrs_to_remove:
            del tag[attr]
        
        # åˆ é™¤javascript:å¼€å¤´çš„hrefå±æ€§
        if tag.get('href') and tag['href'].startswith('javascript:'):
            del tag['href']
    
    # è¿”å›æ¸…ç†åçš„HTML
    return str(soup)
def clean_markdown_content(markdown_content: str) -> str:
    """
    æ¸…ç†Markdownå†…å®¹
    
    Args:
        markdown_content: åŸå§‹Markdownå†…å®¹
        
    Returns:
        str: æ¸…ç†åçš„Markdownå†…å®¹
    """
    # ç§»é™¤å¤šä½™çš„ç©ºè¡Œ
    markdown_content = re.sub(r'\n\s*\n\s*\n', '\n\n', markdown_content)
    
    # ç§»é™¤è¡Œé¦–è¡Œå°¾çš„ç©ºç™½å­—ç¬¦
    lines = [line.strip() for line in markdown_content.split('\n')]
    
    # è¿‡æ»¤ç©ºè¡Œï¼Œä½†ä¿ç•™æ®µè½é—´çš„åˆ†éš”
    cleaned_lines = []
    prev_empty = False
    
    for line in lines:
        if line.strip():
            cleaned_lines.append(line)
            prev_empty = False
        elif not prev_empty:
            cleaned_lines.append('')
            prev_empty = True
    
    # ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„ç©ºè¡Œ
    while cleaned_lines and not cleaned_lines[0]:
        cleaned_lines.pop(0)
    while cleaned_lines and not cleaned_lines[-1]:
        cleaned_lines.pop()
    
    return '\n'.join(cleaned_lines)

def find_main_content_in_cleaned_html(cleaned_body):
    """åœ¨æ¸…ç†åçš„HTMLä¸­æŸ¥æ‰¾ä¸»å†…å®¹åŒºåŸŸ"""
    
    # è·å–æ‰€æœ‰å¯èƒ½çš„å†…å®¹å®¹å™¨
    content_containers = cleaned_body.xpath(".//div | .//section | .//article | .//main")
    
    if not content_containers:
        logger.info("æœªæ‰¾åˆ°å†…å®¹å®¹å™¨ï¼Œè¿”å›body")
        return cleaned_body
    
    # å¯¹å®¹å™¨è¿›è¡Œè¯„åˆ†ï¼ŒåŒæ—¶åˆ é™¤å¤§å¹…åº¦å‡åˆ†çš„æ ‡ç­¾
    scored_containers = []
    containers_to_remove = []
    
    for container in content_containers:
        score = calculate_content_container_score(container)
        
        # å¼ºä¿æŠ¤ï¼šæ£€æŸ¥æ˜¯å¦åŒ…å« printContent æˆ–å…¶ä»–é‡è¦å†…å®¹
        classes = container.get('class', '').lower()
        elem_id = container.get('id', '').lower()
        
        # ç»å¯¹ä¿æŠ¤çš„æ¡ä»¶
        is_protected = (
            'printcontent' in elem_id.lower() or  # printContent ID
            container.xpath(".//*[@id='printContent' or @id='printcontent']") or  # åŒ…å« printContent å­å…ƒç´ 
            'bg-fff' in classes or  # å¸¸è§çš„å†…å®¹å®¹å™¨ç±»å
            'container' in classes and len(container.xpath(".//*")) > 20  # å¤§å‹å®¹å™¨ä¸”å­å…ƒç´ å¤š
        )
        
        if is_protected:
            scored_containers.append((container, max(score, 50)))  # ä¿æŠ¤çš„å®¹å™¨è‡³å°‘ç»™50åˆ†
            logger.info(f"ä¿æŠ¤é‡è¦å®¹å™¨: {container.tag} class='{classes[:30]}' åŸåˆ†æ•°: {score} -> ä¿æŠ¤åˆ†æ•°: {max(score, 50)}")
        elif score < -100:
            containers_to_remove.append(container)
            logger.info(f"æ ‡è®°åˆ é™¤å¤§å¹…å‡åˆ†å®¹å™¨: {container.tag} class='{container.get('class', '')[:30]}' å¾—åˆ†: {score}")
        elif score > -50:  # åªè€ƒè™‘åˆ†æ•°ä¸å¤ªä½çš„å®¹å™¨
            scored_containers.append((container, score))
    
    # ä¸åˆ é™¤ä»»ä½•å®¹å™¨ï¼Œåªæ˜¯æ ‡è®°ä¸ºä¸è€ƒè™‘
    logger.info(f"æ ‡è®°äº† {len(containers_to_remove)} ä¸ªå¤§å¹…å‡åˆ†çš„å®¹å™¨ï¼Œä½†ä¸åˆ é™¤ä»¥ä¿æŠ¤å†…å®¹å®Œæ•´æ€§")
    
    if not scored_containers:
        logger.info("æœªæ‰¾åˆ°æ­£åˆ†å®¹å™¨ï¼Œè¿”å›ç¬¬ä¸€ä¸ªå®¹å™¨")
        return content_containers[0]
    
    # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„å®¹å™¨
    scored_containers.sort(key=lambda x: x[1], reverse=True)
    # best_container = scored_containers[0][0]
    # é€‰æ‹©äº†å¾—åˆ†æ¬¡ä¸€çº§çš„å®¹å™¨
    best_score = scored_containers[0][1]
    
    # ---------------------------------------------------------------------------------------------åŸæ–¹æ³•ï¼Œå¯¹äºæä¸ºå¤æ‚çš„é¡µé¢ä¼šå®šä½çš„â€œè¿‡äºå‡†ç¡®â€
    # same_score_containers = [container for container, score in scored_containers if score == best_score]
    # if len(same_score_containers) > 1:
    #     # æ£€æŸ¥å±‚çº§å…³ç³»ï¼Œå±‚çº§å…³ç³»ã€‚è¿™ä¸€æ­¥ç›´æ¥å½±å“ç»“æœçš„èŒƒå›´ï¼Œå¯¹äºæŸäº›èŒƒå›´å¤§çš„é¡µé¢ï¼Œä½ å¯ä»¥è€ƒè™‘ä¸è·å–æœ€ä½³çš„ï¼Œè€Œè·å–æ¬¡ä½³çš„å®¹å™¨ 
    #     best_container = select_best_from_same_score_containers(same_score_containers)
    # else:
    #     best_container = scored_containers[0][0]
    # logger.info(f"é€‰æ‹©æœ€ä½³å†…å®¹å®¹å™¨ï¼Œå¾—åˆ†: {best_score}")
    # logger.info(f"å®¹å™¨ä¿¡æ¯: {best_container.tag} class='{best_container.get('class', '')[:50]}'")
    # ---------------------------------------------------------------------------------------------
    # è®¾ç½®åˆ†æ•°é˜ˆå€¼ï¼Œè€ƒè™‘åˆ†æ•°ç›¸è¿‘çš„å®¹å™¨ï¼ˆå·®è·åœ¨20åˆ†ä»¥å†…ï¼‰
    score_threshold = 20
    
    # æ‰¾å‡ºåˆ†æ•°åœ¨é˜ˆå€¼èŒƒå›´å†…çš„å®¹å™¨
    similar_score_containers = [(container, score) for container, score in scored_containers 
                               if abs(score - best_score) <= score_threshold]
    
    logger.info(f"æ‰¾åˆ° {len(similar_score_containers)} ä¸ªåˆ†æ•°ç›¸è¿‘çš„å®¹å™¨:")
    for i, (container, score) in enumerate(similar_score_containers):
        logger.info(f"å®¹å™¨{i+1}: {container.tag} class='{container.get('class', '')}' å¾—åˆ†: {score}")
    
    # å¦‚æœæœ‰å¤šä¸ªåˆ†æ•°ç›¸è¿‘çš„å®¹å™¨ï¼Œé€‰æ‹©å±‚çº§æœ€æ·±çš„
    if len(similar_score_containers) > 1:
        # best_container = select_deepest_container_from_similar([c for c, s in similar_score_containers])
        # é€‰æ‹©æœ€ä¼˜çš„
        best_container = select_best_container_prefer_child([c for c, s in similar_score_containers], scored_containers)
    else:
        best_container = scored_containers[0][0]
    # best_container = scored_containers[0][0]
    # è·å–æœ€ç»ˆé€‰æ‹©çš„å®¹å™¨åˆ†æ•°
    final_score = next(score for container, score in scored_containers if container == best_container)
    logger.info(f"æœ€ç»ˆé€‰æ‹©å®¹å™¨ï¼Œå¾—åˆ†: {final_score}")
    logger.info(f"å®¹å™¨ä¿¡æ¯: {best_container.tag} class='{best_container.get('class', '')}'")
    return best_container
def is_child_of(child_element, parent_element):
    """æ£€æŸ¥child_elementæ˜¯å¦æ˜¯parent_elementçš„å­èŠ‚ç‚¹"""
    current = child_element.getparent()
    while current is not None:
        if current == parent_element:
            return True
        current = current.getparent()
    return False

def select_best_container_prefer_child(similar_containers, all_scored_containers):
    """ä»åˆ†æ•°ç›¸è¿‘çš„å®¹å™¨ä¸­é€‰æ‹©æœ€ä½³çš„ï¼Œä¼˜å…ˆé€‰æ‹©å­èŠ‚ç‚¹"""
    
    # æ£€æŸ¥å®¹å™¨ä¹‹é—´çš„çˆ¶å­å…³ç³»
    parent_child_pairs = []
    
    for i, container1 in enumerate(similar_containers):
        for j, container2 in enumerate(similar_containers):
            if i != j:
                # æ£€æŸ¥container2æ˜¯å¦æ˜¯container1çš„å­èŠ‚ç‚¹
                if is_child_of(container2, container1):
                    # è·å–ä¸¤ä¸ªå®¹å™¨çš„åˆ†æ•°
                    score1 = next(score for c, score in all_scored_containers if c == container1)
                    score2 = next(score for c, score in all_scored_containers if c == container2)
                    parent_child_pairs.append((container1, container2, score1, score2))
                    logger.info(f"å‘ç°çˆ¶å­å…³ç³»: çˆ¶å®¹å™¨å¾—åˆ†{score1}, å­å®¹å™¨å¾—åˆ†{score2}")
    
    # å¦‚æœæ‰¾åˆ°çˆ¶å­å…³ç³»ï¼Œéœ€è¦æ›´ä¸¥æ ¼çš„åˆ¤æ–­
    if parent_child_pairs:
        # æ‰¾å‡ºæ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„å­èŠ‚ç‚¹ï¼ˆåˆ†æ•°å·®è·å°äº20åˆ†ï¼Œæ›´ä¸¥æ ¼ï¼‰
        valid_children = []
        for parent, child, parent_score, child_score in parent_child_pairs:
            score_diff = parent_score - child_score
            # åªæœ‰å½“å­èŠ‚ç‚¹åˆ†æ•°å·®è·å¾ˆå°æ—¶æ‰è€ƒè™‘é€‰æ‹©å­èŠ‚ç‚¹
            if score_diff <= 20 and child_score >= 150:  # å­èŠ‚ç‚¹æœ¬èº«åˆ†æ•°è¦è¶³å¤Ÿé«˜
                valid_children.append((child, child_score, score_diff))
        
        if valid_children:
            # æŒ‰åˆ†æ•°æ’åºï¼Œé€‰æ‹©åˆ†æ•°æœ€é«˜çš„å­èŠ‚ç‚¹
            valid_children.sort(key=lambda x: (-x[1], x[2]))  # æŒ‰å­èŠ‚ç‚¹åˆ†æ•°é™åºï¼Œåˆ†å·®å‡åº
            
            best_child, best_score, score_diff = valid_children[0]
            
            # é¢å¤–æ£€æŸ¥ï¼šç¡®ä¿é€‰æ‹©çš„å­èŠ‚ç‚¹ç¡®å®æ¯”çˆ¶èŠ‚ç‚¹æ›´ç²¾ç¡®
            # æ£€æŸ¥å­èŠ‚ç‚¹çš„å†…å®¹å¯†åº¦æ˜¯å¦æ›´é«˜
            child_text_length = len(best_child.text_content().strip())
            parent_candidates = [parent for parent, child, p_score, c_score in parent_child_pairs 
                               if child == best_child]
            
            if parent_candidates:
                parent = parent_candidates[0]
                parent_text_length = len(parent.text_content().strip())
                
                # å¦‚æœå­èŠ‚ç‚¹çš„å†…å®¹é•¿åº¦ä¸åˆ°çˆ¶èŠ‚ç‚¹çš„60%ï¼Œå¯èƒ½é€‰æ‹©äº†é”™è¯¯çš„å­èŠ‚ç‚¹
                if child_text_length < parent_text_length * 0.6:
                    logger.info(f"å­èŠ‚ç‚¹å†…å®¹è¿‡å°‘({child_text_length} vs {parent_text_length})ï¼Œé€‰æ‹©çˆ¶èŠ‚ç‚¹")
                    return parent
            
            logger.info(f"é€‰æ‹©å­å®¹å™¨: {best_child.tag} class='{best_child.get('class', '')}' (çˆ¶å­åˆ†å·®: {score_diff})")
            return best_child
    
    # å¦‚æœæ²¡æœ‰åˆé€‚çš„çˆ¶å­å…³ç³»ï¼Œä½¿ç”¨åŸæ¥çš„å±‚çº§æ·±åº¦é€‰æ‹©é€»è¾‘
    return select_deepest_container_from_similar(similar_containers)
def select_deepest_container_from_similar(similar_containers):
    """ä»åˆ†æ•°ç›¸è¿‘çš„å®¹å™¨ä¸­é€‰æ‹©å±‚çº§æœ€æ·±çš„ä¸€ä¸ª"""
    if not similar_containers:
        return None
    
    if len(similar_containers) == 1:
        return similar_containers[0]
    
    # è®¡ç®—æ¯ä¸ªå®¹å™¨çš„å±‚çº§æ·±åº¦
    container_depths = []
    for container in similar_containers:
        depth = calculate_container_depth(container)
        container_depths.append((container, depth))
        logger.info(f"  å€™é€‰å®¹å™¨å±‚çº§æ·±åº¦: {depth} - {container.tag} class='{container.get('class', '')}'")
    
    # æŒ‰å±‚çº§æ·±åº¦æ’åºï¼ˆæ·±åº¦è¶Šå¤§ï¼Œå±‚çº§è¶Šæ·±ï¼‰
    container_depths.sort(key=lambda x: x[1], reverse=True)
    
    # é€‰æ‹©å±‚çº§æœ€æ·±çš„å®¹å™¨
    deepest_container = container_depths[0][0]
    deepest_depth = container_depths[0][1]
    
    logger.info(f"é€‰æ‹©æœ€æ·±å±‚å®¹å™¨ (æ·±åº¦ {deepest_depth}): {deepest_container.tag} class='{deepest_container.get('class', '')}'")
    return deepest_container

def calculate_container_depth(container):
    """è®¡ç®—å®¹å™¨è·ç¦»bodyçš„å±‚çº§æ·±åº¦"""
    depth = 0
    current = container
    
    # å‘ä¸Šéå†ç›´åˆ°bodyæˆ–html
    while current is not None and current.tag not in ['body', 'html']:
        depth += 1
        current = current.getparent()
        if current is None:
            break
    
    return depth
def select_best_from_same_score_containers(containers):
    """ä»å¾—åˆ†ç›¸åŒçš„å¤šä¸ªå®¹å™¨ä¸­é€‰æ‹©å±‚çº§æœ€æ·±çš„ä¸€ä¸ªï¼ˆå„¿å­å®¹å™¨ï¼‰"""
    # æ£€æŸ¥å®¹å™¨ä¹‹é—´çš„å±‚çº§å…³ç³»ï¼Œé€‰æ‹©å±‚çº§æœ€æ·±çš„
    container_depths = []
    
    for container in containers:
        # è®¡ç®—å®¹å™¨çš„å±‚çº§æ·±åº¦ï¼ˆè·ç¦»bodyçš„å±‚çº§æ•°ï¼‰
        depth = calculate_container_depth(container)
        container_depths.append((container, depth))
        
        logger.info(f"å®¹å™¨å±‚çº§æ·±åº¦: {depth} - {container.tag} class='{container.get('class', '')[:30]}'")
    
    # æŒ‰å±‚çº§æ·±åº¦æ’åºï¼ˆæ·±åº¦è¶Šå¤§ï¼Œå±‚çº§è¶Šæ·±ï¼‰
    container_depths.sort(key=lambda x: x[1], reverse=True)
    
    # é€‰æ‹©å±‚çº§æœ€æ·±çš„å®¹å™¨ï¼ˆå„¿å­å®¹å™¨ï¼‰
    best_container = container_depths[0][0]
    best_depth = container_depths[0][1]
    
    logger.info(f"é€‰æ‹©å±‚çº§æœ€æ·±çš„å®¹å™¨ (æ·±åº¦ {best_depth}): {best_container.tag} class='{best_container.get('class', '')[:30]}'")
    
    return best_container

def calculate_container_depth(container):
    """è®¡ç®—å®¹å™¨è·ç¦»bodyçš„å±‚çº§æ·±åº¦"""
    depth = 0
    current = container
    
    # å‘ä¸Šéå†ç›´åˆ°bodyæˆ–html
    while current is not None and current.tag not in ['body', 'html']:
        depth += 1
        current = current.getparent()
        if current is None:
            break
    
    return depth
def calculate_content_container_score(container):
    """è®¡ç®—å†…å®¹å®¹å™¨å¾—åˆ† - ä¸“æ³¨äºè¯†åˆ«çœŸæ­£çš„å†…å®¹åŒºåŸŸï¼Œå¤§å¹…åº¦å‡åˆ†å¹²æ‰°æ ‡ç­¾"""
    score = 0
    debug_info = []
    
    classes = container.get('class', '').lower()
    elem_id = container.get('id', '').lower()
    text_content = container.text_content()
    text_length = len(text_content.strip())

    logger.info(f"\n=== å¼€å§‹è¯„åˆ†å®¹å™¨ ===")
    logger.info(f"æ ‡ç­¾: {container.tag}")
    logger.info(f"ç±»å: {classes[:100]}{'...' if len(classes) > 100 else ''}")
    logger.info(f"ID: {elem_id[:50]}{'...' if len(elem_id) > 50 else ''}")
    logger.info(f"æ–‡æœ¬é•¿åº¦: {text_length}")

    # # ç‰¹æ®ŠIDåŠ åˆ† - printContenté€šå¸¸æ˜¯ä¸»è¦å†…å®¹åŒºåŸŸ
    # special_id_keywords = ['printcontent', 'printContent']
    # for keyword in special_id_keywords:
    #     if keyword.lower() in elem_id.lower():
    #         if 'printcontent' in keyword.lower():
    #             score += 200  # printContentç»™æœ€é«˜åˆ†
    #             debug_info.append("âœ“ printContent IDç‰¹å¾: +200")
    #         else:
    #             score += 100  # å…¶ä»–å†…å®¹IDä¹Ÿç»™é«˜åˆ†
    #             debug_info.append(f"âœ“ å†…å®¹IDç‰¹å¾: +100 ({keyword})")
    #         break
    # é¦–å…ˆè¿›è¡Œå¤§å¹…åº¦å‡åˆ†æ£€æŸ¥ - ç›´æ¥æ’é™¤å¹²æ‰°æ ‡ç­¾
    # 1. æ£€æŸ¥æ ‡ç­¾å - ç›´æ¥æ’é™¤
    if container.tag.lower() in ['header', 'footer', 'nav', 'aside']:
        score -= 500  # æå¤§å‡åˆ†ï¼ŒåŸºæœ¬æ’é™¤
        debug_info.append(f"âŒ å¹²æ‰°æ ‡ç­¾: -{500} ({container.tag}) - ç›´æ¥æ’é™¤")
        logger.info(f"âŒ å‘ç°å¹²æ‰°æ ‡ç­¾ {container.tag}ï¼Œç›´æ¥æ’é™¤ï¼Œå¾—åˆ†: {score}")
        return score  # ç›´æ¥è¿”å›ï¼Œä¸å†è®¡ç®—å…¶ä»–åˆ†æ•°
    
    # -------------------------------------------------------------------------
    # 2. æ£€æŸ¥å¼ºçƒˆçš„å¹²æ‰°ç±»å/ID - å¤§å¹…å‡åˆ†
    # strong_interference_keywords = [
    #     'header', 'footer', 'nav', 'navigation', 'menu', 'menubar', 
    #     'topbar', 'bottom', 'sidebar', 'aside', 'banner', 'ad', 'advertisement'
    # ]
    
    # interference_count = 0
    # found_interference_keywords = []
    # for keyword in strong_interference_keywords:
    #     if keyword in classes or keyword in elem_id:
    #         interference_count += 1
    #         found_interference_keywords.append(keyword)
    
    # if interference_count > 0:
    #     interference_penalty = interference_count * 200  # æ¯ä¸ªå¹²æ‰°å…³é”®è¯å‡200åˆ†
    #     score -= interference_penalty
    #     debug_info.append(f"âŒ å¼ºå¹²æ‰°ç‰¹å¾: -{interference_penalty} (å‘ç°{interference_count}ä¸ª: {', '.join(found_interference_keywords)})")
    #     logger.info(f"âŒ å‘ç°å¼ºå¹²æ‰°ç‰¹å¾: {', '.join(found_interference_keywords)}ï¼Œå‡åˆ†: {interference_penalty}")
        
    #     # å¦‚æœå¹²æ‰°ç‰¹å¾å¤ªå¤šï¼Œç›´æ¥è¿”å›è´Ÿåˆ†
    #     if interference_count >= 2:
    #         logger.info(f"âŒ å¹²æ‰°ç‰¹å¾è¿‡å¤š({interference_count}ä¸ª)ï¼Œç›´æ¥è¿”å›è´Ÿåˆ†: {score}")
    #         return score
    # ----------------------------------------------------------------------------

    # 2. æ£€æŸ¥å¼ºçƒˆçš„å¹²æ‰°ç±»å/ID - å¤§å¹…å‡åˆ†
    strong_interference_keywords = [
        'header', 'footer', 'nav', 'navigation', 'menu', 'menubar', 
        'topbar', 'bottom', 'sidebar', 'aside', 'banner', 'ad', 'advertisement'
    ]

    def create_pattern(keyword):
        # åŒ¹é…å•è¯è¾¹ç•Œï¼Œæˆ–è¢« -/_/space åŒ…å›´
        return re.compile(r'(^|[^\w-])' + re.escape(keyword) + r'([^\w-]|$)', re.IGNORECASE)

    interference_patterns = {kw: create_pattern(kw) for kw in strong_interference_keywords}

    interference_count = 0
    found_interference_keywords = []

    # "main-nav sidebar ad-banner"
    combined_text = f"{classes} {elem_id}".strip().lower()

    for keyword, pattern in interference_patterns.items():
        if pattern.search(combined_text):
            interference_count += 1
            found_interference_keywords.append(keyword)

    if interference_count > 0:
        interference_penalty = interference_count * 200
        score -= interference_penalty
        debug_info.append(f"âŒ å¼ºå¹²æ‰°ç‰¹å¾: -{interference_penalty} (å‘ç°{interference_count}ä¸ª: {', '.join(found_interference_keywords)})")
        logger.info(f"âŒ å‘ç°å¼ºå¹²æ‰°ç‰¹å¾: {', '.join(found_interference_keywords)}ï¼Œå‡åˆ†: {interference_penalty}")
        
        if interference_count >= 2:
            logger.info(f"âŒ å¹²æ‰°ç‰¹å¾è¿‡å¤š({interference_count}ä¸ª)ï¼Œç›´æ¥è¿”å›è´Ÿåˆ†: {score}")
            return score

    # 3. æ£€æŸ¥å†…å®¹ç‰¹å¾ - è¯†åˆ«é¦–éƒ¨å°¾éƒ¨å†…å®¹
    header_content_keywords = [
        'ç™»å½•', 'æ³¨å†Œ', 'é¦–é¡µ', 'ä¸»é¡µ', 'æ— éšœç¢', 'æ”¿åŠ¡', 'åŠäº‹', 'äº’åŠ¨', 
        'èµ°è¿›', 'ç§»åŠ¨ç‰ˆ', 'æ‰‹æœºç‰ˆ', 'å¯¼èˆª', 'èœå•', 'æœç´¢', 'å¸‚æ”¿åºœ',
        'login', 'register', 'home', 'menu', 'search', 'nav'
    ]
    
    footer_content_keywords = [
        'ç½‘ç«™è¯´æ˜', 'ç½‘ç«™æ ‡è¯†ç ', 'ç‰ˆæƒæ‰€æœ‰', 'ä¸»åŠå•ä½', 'æ‰¿åŠå•ä½', 
        'æŠ€æœ¯æ”¯æŒ', 'è”ç³»æˆ‘ä»¬', 'ç½‘ç«™åœ°å›¾', 'éšç§æ”¿ç­–', 'å…è´£å£°æ˜',
        'å¤‡æ¡ˆå·', 'icp', 'å…¬å®‰å¤‡æ¡ˆ', 'æ”¿åºœç½‘ç«™', 'ç½‘ç«™ç®¡ç†',
        'copyright', 'all rights reserved', 'powered by', 'designed by'
    ]
    
    # è¯¦ç»†è®°å½•æ‰¾åˆ°çš„å…³é”®è¯
    found_header_keywords = [keyword for keyword in header_content_keywords if keyword in text_content.lower() and not (('å½“å‰ä½ç½®' in text_content.lower()) or ('å½“å‰çš„ä½ç½®' in  text_content.lower())) ]
    found_footer_keywords = [keyword for keyword in footer_content_keywords if keyword in text_content.lower()]
    
    header_content_count = len(found_header_keywords)
    footer_content_count = len(found_footer_keywords)
    
    logger.info(f"ğŸ“ å†…å®¹ç‰¹å¾åˆ†æ:")
    logger.info(f"   é¦–éƒ¨å…³é”®è¯({header_content_count}ä¸ª): {found_header_keywords}")
    logger.info(f"   å°¾éƒ¨å…³é”®è¯({footer_content_count}ä¸ª): {found_footer_keywords}")
    
    # TODO: éƒ¨åˆ†é¡µé¢æ­£æ–‡ä¸­ä¹Ÿä¼šåŒ…å«é¦–éƒ¨ï¼ˆä¸ä¼šåŒ…å«å°¾éƒ¨ï¼‰ï¼Œæ‰€ä»¥ï¼Œå¯¹äºè¿™éƒ¨åˆ†è¦ç‰¹æ®Šè¯†åˆ«ã€‚ 

    

    # å¤§å¹…å‡åˆ†é¦–éƒ¨å°¾éƒ¨å†…å®¹
    if header_content_count >= 3:
        score -= 300
        debug_info.append(f"âŒ é¦–éƒ¨å†…å®¹: -300 (å‘ç°{header_content_count}ä¸ªå…³é”®è¯: {', '.join(found_header_keywords)})")
        logger.info(f"âŒ é¦–éƒ¨å†…å®¹è¿‡å¤šï¼Œå‡åˆ†300")
    elif header_content_count >= 2:
        score -= 150
        debug_info.append(f"âŒ é¦–éƒ¨å†…å®¹: -150 (å‘ç°{header_content_count}ä¸ªå…³é”®è¯: {', '.join(found_header_keywords)})")
        logger.info(f"âŒ é¦–éƒ¨å†…å®¹è¾ƒå¤šï¼Œå‡åˆ†150")
    

    if footer_content_count >= 3:
        score -= 300
        debug_info.append(f"âŒ å°¾éƒ¨å†…å®¹: -300 (å‘ç°{footer_content_count}ä¸ªå…³é”®è¯: {', '.join(found_footer_keywords)})")
        logger.info(f"âŒ å°¾éƒ¨å†…å®¹è¿‡å¤šï¼Œå‡åˆ†300")
    elif footer_content_count >= 2:
        score -= 150
        debug_info.append(f"âŒ å°¾éƒ¨å†…å®¹: -150 (å‘ç°{footer_content_count}ä¸ªå…³é”®è¯: {', '.join(found_footer_keywords)})")
        logger.info(f"âŒ å°¾éƒ¨å†…å®¹è¾ƒå¤šï¼Œå‡åˆ†150")
    
    # å¦‚æœå·²ç»æ˜¯ä¸¥é‡è´Ÿåˆ†ï¼Œä¸å†ç»§ç»­è®¡ç®—
    if score < -200:
        logger.info(f"âŒ å½“å‰å¾—åˆ†è¿‡ä½({score})ï¼Œåœæ­¢åç»­è®¡ç®—")
        debug_info.append(f"âŒ å¾—åˆ†è¿‡ä½ï¼Œåœæ­¢è®¡ç®—: {score}")
        return score
    
    # 4. åŸºç¡€å†…å®¹é•¿åº¦è¯„åˆ†
    logger.info(f"ğŸ“ å†…å®¹é•¿åº¦è¯„åˆ†: {text_length}å­—ç¬¦")
    if text_length > 1000:
        score += 50
        debug_info.append("âœ“ é•¿å†…å®¹: +50")
        logger.info(f"âœ“ é•¿å†…å®¹åŠ åˆ†: +50")
    elif text_length > 500:
        score += 35
        debug_info.append("âœ“ ä¸­ç­‰å†…å®¹: +35")
        logger.info(f"âœ“ ä¸­ç­‰å†…å®¹åŠ åˆ†: +35")
    elif text_length > 200:
        score += 20
        debug_info.append("âœ“ çŸ­å†…å®¹: +20")
        logger.info(f"âœ“ çŸ­å†…å®¹åŠ åˆ†: +20")
    elif text_length < 50:
        score -= 20
        debug_info.append("âŒ å†…å®¹å¤ªå°‘: -20")
        logger.info(f"âŒ å†…å®¹å¤ªå°‘å‡åˆ†: -20")
    
    # 5. Roleå±æ€§æ£€æŸ¥
    role = container.get('role', '').lower()
    logger.info(f"ğŸ­ Roleå±æ€§: '{role}'")
    if role == 'viewlist':
        score += 150
        debug_info.append("âœ“ Roleç‰¹å¾: +150 (role='viewlist')")
        logger.info(f"âœ“ å‘ç°viewlistè§’è‰²ï¼ŒåŠ åˆ†150")
    elif role in ['list', 'listbox', 'grid', 'main', 'article']:
        score += 50
        debug_info.append(f"âœ“ Roleç‰¹å¾: +50 (role='{role}')")
        logger.info(f"âœ“ å‘ç°{role}è§’è‰²ï¼ŒåŠ åˆ†50")
    
    # 6. å†…å®¹ç‰¹å¾æ£€æµ‹ - ä¸é™äºåˆ—è¡¨
    content_indicators = [
        # æ—¶é—´ç‰¹å¾
        (r'\d{4}-\d{2}-\d{2}|\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥|\d{4}/\d{1,2}/\d{1,2}|å‘å¸ƒæ—¶é—´|æ›´æ–°æ—¥æœŸ|å‘å¸ƒæ—¥æœŸ|æˆæ–‡æ—¥æœŸ', 30, 'æ—¶é—´ç‰¹å¾'),
        # å…¬æ–‡ç‰¹å¾
        (r'é€šçŸ¥|å…¬å‘Š|æ„è§|åŠæ³•|è§„å®š|æªæ–½|æ–¹æ¡ˆ|å†³å®š|æŒ‡å¯¼|å®æ–½', 40, 'å…¬æ–‡ç‰¹å¾'),
        # æ¡æ¬¾ç‰¹å¾
        (r'ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+æ¡|ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+ç« |ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+èŠ‚', 35, 'æ¡æ¬¾ç‰¹å¾'),
        # æ”¿åŠ¡ä¿¡æ¯ç‰¹å¾
        (r'ç´¢å¼•å·|ä¸»é¢˜åˆ†ç±»|å‘æ–‡æœºå…³|å‘æ–‡å­—å·|æœ‰æ•ˆæ€§', 25, 'æ”¿åŠ¡ä¿¡æ¯'),
        # é™„ä»¶ç‰¹å¾
        (r'é™„ä»¶|ä¸‹è½½|pdf|doc|docx|æ–‡ä»¶ä¸‹è½½', 20, 'é™„ä»¶ç‰¹å¾'),
        # å†…å®¹ç»“æ„ç‰¹å¾
        (r'ä¸ºäº†|æ ¹æ®|æŒ‰ç…§|ä¾æ®|ç°å°†|ç‰¹åˆ¶å®š|ç°å°å‘|è¯·ç»“åˆå®é™…', 30, 'å†…å®¹ç»“æ„'),
        # æ–°é—»å†…å®¹ç‰¹å¾
        (r'è®°è€…|æŠ¥é“|æ¶ˆæ¯|æ–°é—»|é‡‡è®¿|å‘è¡¨|åˆŠç™»', 25, 'æ–°é—»ç‰¹å¾'),
        # æ­£æ–‡å†…å®¹ç‰¹å¾
        (r'æ­£æ–‡|å†…å®¹|è¯¦æƒ…|å…¨æ–‡|æ‘˜è¦|æ¦‚è¿°', 20, 'æ­£æ–‡ç‰¹å¾')
    ]
    
    total_content_score = 0
    matched_features = []
    
    logger.info(f"ğŸ” å†…å®¹ç‰¹å¾æ£€æµ‹:")
    for pattern, weight, feature_name in content_indicators:
        matches = re.findall(pattern, text_content)
        if matches:
            total_content_score += weight
            matched_features.append(f"{feature_name}({len(matches)})")
            logger.info(f"   âœ“ {feature_name}: æ‰¾åˆ°{len(matches)}ä¸ªåŒ¹é…ï¼ŒåŠ åˆ†{weight}")
    
    if total_content_score > 0:
        final_content_score = min(total_content_score, 120)
        score += final_content_score
        debug_info.append(f"âœ“ å†…å®¹ç‰¹å¾: +{final_content_score} ({','.join(matched_features)})")
        logger.info(f"âœ“ å†…å®¹ç‰¹å¾æ€»åŠ åˆ†: {final_content_score} (åŸå§‹åˆ†æ•°: {total_content_score})")
    else:
        logger.info(f"   âŒ æœªå‘ç°å†…å®¹ç‰¹å¾")
    
    # 7. æ­£é¢ç±»å/IDç‰¹å¾
    positive_keywords = [
        'content', 'main', 'article', 'news', 'data', 'info', 
        'detail', 'result', 'list', 'body', 'text', 'container'
    ]
    
    positive_matches = 0
    for keyword in positive_keywords:
        if keyword in classes or keyword in elem_id:
            positive_matches += 1
    
    if positive_matches > 0:
        positive_score = min(positive_matches * 20, 60)
        score += positive_score
        debug_info.append(f"æ­£é¢ç‰¹å¾: +{positive_score}")
    
    # 8. ç»“æ„åŒ–å†…å®¹æ£€æµ‹ - ä¸é™äºåˆ—è¡¨
    structured_elements = container.xpath(".//p | .//h1 | .//h2 | .//h3 | .//h4 | .//h5 | .//h6 | .//li | .//table | .//div[contains(@class,'content')] | .//section")
    if len(structured_elements) > 5:
        structure_score = min(len(structured_elements) * 2, 40)
        score += structure_score
        debug_info.append(f"ç»“æ„åŒ–å†…å®¹: +{structure_score}")
    
    # 9. å›¾ç‰‡å†…å®¹
    images = container.xpath(".//img")
    if len(images) > 0:
        image_score = min(len(images) * 3, 150)
        score += image_score
        debug_info.append(f"å›¾ç‰‡å†…å®¹: +{image_score}")
    
    # è¾“å‡ºè°ƒè¯•ä¿¡æ¯
    container_info = f"{container.tag} class='{classes[:30]}'"
    logger.info(f"å®¹å™¨è¯„åˆ†: {score} - {container_info}")
    for info in debug_info:
        logger.info(f"  {info}")
    
    return score

def exclude_page_header_footer(body):
    """æ’é™¤é¡µé¢çº§åˆ«çš„headerå’Œfooter"""
    children = body.xpath("./div | ./main | ./section | ./article")
    
    if not children:
        return body
    
    valid_children = []
    for child in children:
        if not is_page_level_header_footer(child):
            valid_children.append(child)
    
    return find_middle_content(valid_children)

def is_page_level_header_footer(element):
    """åˆ¤æ–­æ˜¯å¦æ˜¯é¡µé¢çº§åˆ«çš„headeræˆ–footer - æ›´ä¸¥æ ¼çš„æ£€æŸ¥"""
    classes = element.get('class', '').lower()
    elem_id = element.get('id', '').lower()
    tag_name = element.tag.lower()
    
    # æ£€æŸ¥æ ‡ç­¾å
    if tag_name in ['header', 'footer', 'nav']:
        return True
    
    # æ£€æŸ¥æ˜¯å¦åœ¨footeråŒºåŸŸ
    is_footer, _ = is_in_footer_area(element)
    if is_footer:
        return True
    
    # æ£€æŸ¥é¡µé¢çº§åˆ«çš„header/footerç‰¹å¾
    page_keywords = ['header', 'footer', 'nav', 'menu', 'topbar', 'bottom', 'top']
    for keyword in page_keywords:
        if keyword in classes or keyword in elem_id:
            return True
    
    # æ£€æŸ¥roleå±æ€§
    role = element.get('role', '').lower()
    if role in ['banner', 'navigation', 'contentinfo']:
        return True
    
    return False

def find_middle_content(valid_children):
    """ä»æœ‰æ•ˆå­å…ƒç´ ä¸­æ‰¾åˆ°ä¸­é—´çš„ä¸»è¦å†…å®¹"""
    if not valid_children:
        return None
    
    if len(valid_children) == 1:
        return valid_children[0]
    
    # è®¡ç®—æ¯ä¸ªå®¹å™¨çš„å†…å®¹å¾—åˆ†
    scored_containers = []
    for container in valid_children:
        score = calculate_content_richness(container)
        scored_containers.append((container, score))
    
    # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„å®¹å™¨
    scored_containers.sort(key=lambda x: x[1], reverse=True)
    best_container = scored_containers[0][0]
    
    logger.info(f"é¡µé¢ä¸»ä½“å®¹å™¨å¾—åˆ†: {scored_containers[0][1]}")
    return best_container

def calculate_content_richness(container):
    """è®¡ç®—å®¹å™¨çš„å†…å®¹ä¸°å¯Œåº¦"""
    score = 0
    
    text_content = container.text_content().strip()
    content_length = len(text_content)
    
    if content_length > 1000:
        score += 40
    elif content_length > 500:
        score += 30
    elif content_length > 200:
        score += 20
    elif content_length > 100:
        score += 10
    else:
        return -5
    
    # æ£€æŸ¥å›¾ç‰‡æ•°é‡
    images = container.xpath(".//img")
    if len(images) > 0:
        score += min(len(images) * 3, 20)
    
    # æ£€æŸ¥ç»“æ„åŒ–å†…å®¹
    structured_elements = container.xpath(".//p | .//div[contains(@style, 'text-align')] | .//h1 | .//h2 | .//h3")
    if len(structured_elements) > 0:
        score += min(len(structured_elements) * 2, 25)
    
    return score

def exclude_local_header_footer(container):
    """åœ¨å®¹å™¨å†…éƒ¨æ’é™¤å±€éƒ¨çš„headerå’Œfooter"""
    children = container.xpath("./div | ./section | ./article")
    
    if not children:
        return container
    
    valid_children = []
    for child in children:
        if not is_local_header_footer(child):
            valid_children.append(child)
    
    if not valid_children:
        return container
    
    return select_content_container(valid_children)

def is_local_header_footer(element):
    """åˆ¤æ–­æ˜¯å¦æ˜¯å±€éƒ¨çš„headeræˆ–footer"""
    classes = element.get('class', '').lower()
    elem_id = element.get('id', '').lower()
    
    # æ£€æŸ¥å±€éƒ¨header/footerç‰¹å¾
    local_keywords = ['title', 'tit', 'head', 'foot', 'top', 'bottom', 'nav', 'menu']
    for keyword in local_keywords:
        if keyword in classes or keyword in elem_id:
            # è¿›ä¸€æ­¥æ£€æŸ¥æ˜¯å¦çœŸçš„æ˜¯header/footer
            text_content = element.text_content().strip()
            if len(text_content) < 200:  # å†…å®¹è¾ƒå°‘ï¼Œå¯èƒ½æ˜¯æ ‡é¢˜æˆ–å¯¼èˆª
                return True
    
    return False

def select_content_container(valid_children):
    """ä»æœ‰æ•ˆå­å®¹å™¨ä¸­é€‰æ‹©æœ€ä½³çš„å†…å®¹å®¹å™¨"""
    if len(valid_children) == 1:
        return valid_children[0]
    
    # è®¡ç®—æ¯ä¸ªå®¹å™¨çš„å¾—åˆ†
    scored_containers = []
    for container in valid_children:
        score = calculate_final_score(container)
        scored_containers.append((container, score))
    
    # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„å®¹å™¨
    scored_containers.sort(key=lambda x: x[1], reverse=True)
    best_container = scored_containers[0][0]
    
    return best_container

def calculate_final_score(container):
    """è®¡ç®—æœ€ç»ˆå®¹å™¨å¾—åˆ†"""
    score = 0
    
    text_content = container.text_content().strip()
    content_length = len(text_content)
    
    if content_length > 500:
        score += 30
    elif content_length > 200:
        score += 20
    elif content_length > 100:
        score += 15
    else:
        score += 5
    
    # æ£€æŸ¥å›¾ç‰‡
    images = container.xpath(".//img")
    if len(images) > 0:
        score += min(len(images) * 4, 25)
    
    # æ£€æŸ¥ç»“æ„åŒ–å†…å®¹
    styled_divs = container.xpath(".//div[contains(@style, 'text-align')]")
    paragraphs = container.xpath(".//p")
    
    structure_count = len(styled_divs) + len(paragraphs)
    if structure_count > 0:
        score += min(structure_count * 2, 20)
    
    # æ£€æŸ¥ç±»åç‰¹å¾
    classes = container.get('class', '').lower()
    elem_id = container.get('id', '').lower()
    
    content_keywords = ['content', 'article', 'detail', 'main', 'body', 'text', 'editor', 'con']
    for keyword in content_keywords:
        if keyword in classes or keyword in elem_id:
            score += 15
    
    return score

def find_main_content_area(containers):
    """åœ¨æœ‰æ•ˆå®¹å™¨ä¸­æ‰¾åˆ°ä¸»å†…å®¹åŒºåŸŸ"""
    candidates = []
    
    for container in containers:
        score = calculate_main_content_score(container)
        if score > 0:
            candidates.append((container, score))
    
    if not candidates:
        return None
    
    # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„ä½œä¸ºä¸»å†…å®¹åŒºåŸŸ
    candidates.sort(key=lambda x: x[1], reverse=True)
    main_area = candidates[0][0]
    
    logger.info(f"ä¸»å†…å®¹åŒºåŸŸå¾—åˆ†: {candidates[0][1]}")
    return main_area

def calculate_main_content_score(container):
    """è®¡ç®—ä¸»å†…å®¹åŒºåŸŸå¾—åˆ†"""
    score = 0
    
    text_content = container.text_content().strip()
    content_length = len(text_content)
    
    # å†…å®¹é•¿åº¦æ˜¯ä¸»è¦æŒ‡æ ‡
    if content_length > 500:
        score += 30
    elif content_length > 200:
        score += 20
    elif content_length > 100:
        score += 10
    else:
        return -5  # å†…å®¹å¤ªå°‘
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸°å¯Œå†…å®¹
    images = container.xpath(".//img")
    if len(images) > 0:
        score += min(len(images) * 2, 15)
    
    # æ£€æŸ¥ç±»åç‰¹å¾
    classes = container.get('class', '').lower()
    elem_id = container.get('id', '').lower()
    
    content_keywords = ['content', 'main', 'article', 'detail', 'body']
    for keyword in content_keywords:
        if keyword in classes or keyword in elem_id:
            score += 15
    
    return score


    
    # æ£€æŸ¥ç±»å
    classes = container.get('class', '').lower()
    if any(word in classes for word in ['content', 'article', 'detail', 'editor', 'text']):
        score += 15
    
    return score



def is_in_footer_area(element):
    """æ£€æŸ¥å…ƒç´ æ˜¯å¦åœ¨footeråŒºåŸŸ"""
    current = element
    depth = 0
    while current is not None and depth < 10:  # æ£€æŸ¥10å±‚ç¥–å…ˆ
        classes = current.get('class', '').lower()
        elem_id = current.get('id', '').lower()
        tag_name = current.tag.lower()
        
        # æ£€æŸ¥footerç›¸å…³ç‰¹å¾
        footer_indicators = [
            'footer', 'bottom', 'foot', 'end', 'copyright', 
            'links', 'sitemap', 'contact', 'about'
        ]
        
        for indicator in footer_indicators:
            if (indicator in classes or indicator in elem_id or 
                (tag_name == 'footer')):
                return True, f"å‘ç°footerç‰¹å¾: {indicator} (ç¬¬{depth}å±‚)"
        
        # æ£€æŸ¥æ˜¯å¦åœ¨é¡µé¢åº•éƒ¨åŒºåŸŸï¼ˆé€šè¿‡æ ·å¼æˆ–ä½ç½®åˆ¤æ–­ï¼‰
        style = current.get('style', '').lower()
        if 'bottom' in style or 'fixed' in style:
            return True, f"å‘ç°åº•éƒ¨æ ·å¼ (ç¬¬{depth}å±‚)"
        
        current = current.getparent()
        depth += 1
    
    return False, ""

def find_list_container(page_tree):
    # é¦–å…ˆå°è¯•ä½¿ç”¨æ”¹è¿›çš„æ–‡ç« å®¹å™¨æŸ¥æ‰¾ç®—æ³•
    article_container = find_article_container(page_tree)
    if article_container is not None:
        return article_container    
    list_selectors = [
        "//li", "//tr", "//article",
        "//div[contains(@class, 'item')]",
        "//div[contains(@class, 'list')]",
        "//ul//li", "//ol//li", "//table//tr",
        "//section//ul[contains(@class, 'item')]",
        "//section//ul[contains(@class, 'list')]",
        "//section//div[contains(@class, 'list')]",
        "//section//div[contains(@class, 'item')]"
    ]
    
    def count_list_items(element):
        items = element.xpath(".//li | .//tr | .//article | .//div[contains(@class, 'item')]")
        return len(items)
    
    def calculate_container_score(container):
        """è®¡ç®—å®¹å™¨ä½œä¸ºç›®æ ‡åˆ—è¡¨çš„å¾—åˆ† - ç¬¬ä¸€è½®ä¸¥æ ¼è¿‡æ»¤é¦–éƒ¨å°¾éƒ¨"""
        score = 0
        debug_info = []
        
        # è·å–å®¹å™¨çš„åŸºæœ¬ä¿¡æ¯
        classes = container.get('class', '').lower()
        elem_id = container.get('id', '').lower()
        role = container.get('role', '').lower()
        tag_name = container.tag.lower()
        text_content = container.text_content().lower()
        
        # ç¬¬ä¸€è½®è¿‡æ»¤ï¼šæ ¹æ®å†…å®¹ç‰¹å¾ç›´æ¥æ’é™¤é¦–éƒ¨å’Œå°¾éƒ¨å®¹å™¨
        # 1. æ£€æŸ¥é¦–éƒ¨ç‰¹å¾å†…å®¹
        header_content_keywords = [
            'ç™»å½•', 'æ³¨å†Œ', 'é¦–é¡µ', 'ä¸»é¡µ', 'æ— éšœç¢', 'æ”¿åŠ¡', 'åŠäº‹', 'äº’åŠ¨', 
            'èµ°è¿›', 'ç§»åŠ¨ç‰ˆ', 'æ‰‹æœºç‰ˆ', 'å¯¼èˆª', 'èœå•', 'æœç´¢', 'å¸‚æ”¿åºœ',
            'é•¿è€…æ¨¡å¼','å¾®ä¿¡','ipv6','ä¿¡æ¯å…¬å¼€',
            'login', 'register', 'home', 'menu', 'search', 'nav'
        ]
        
        header_content_count = 0
        for keyword in header_content_keywords:
            if keyword in text_content:
                header_content_count += 1
        
        # å¦‚æœåŒ…å«å¤šä¸ªé¦–éƒ¨å…³é”®è¯ï¼Œä¸¥é‡å‡åˆ†
        if header_content_count >= 2:
            score -= 300  # æä¸¥é‡å‡åˆ†ï¼ŒåŸºæœ¬æ’é™¤
            debug_info.append(f"é¦–éƒ¨å†…å®¹ç‰¹å¾: -300 (å‘ç°{header_content_count}ä¸ªé¦–éƒ¨å…³é”®è¯)")
        
        # 2. æ£€æŸ¥å°¾éƒ¨ç‰¹å¾å†…å®¹
        footer_content_keywords = [
            'ç½‘ç«™è¯´æ˜', 'ç½‘ç«™æ ‡è¯†ç ', 'ç‰ˆæƒæ‰€æœ‰', 'ä¸»åŠå•ä½', 'æ‰¿åŠå•ä½', 
            'æŠ€æœ¯æ”¯æŒ', 'è”ç³»æˆ‘ä»¬', 'ç½‘ç«™åœ°å›¾', 'éšç§æ”¿ç­–', 'å…è´£å£°æ˜',
            'å¤‡æ¡ˆå·', 'icp', 'å…¬å®‰å¤‡æ¡ˆ', 'æ”¿åºœç½‘ç«™', 'ç½‘ç«™ç®¡ç†',
            'copyright', 'all rights reserved', 'powered by', 'designed by'
        ]
        
        footer_content_count = 0
        for keyword in footer_content_keywords:
            if keyword in text_content:
                footer_content_count += 1
        
        # å¦‚æœåŒ…å«å¤šä¸ªå°¾éƒ¨å…³é”®è¯ï¼Œä¸¥é‡å‡åˆ†
        if footer_content_count >= 2:
            score -= 300  # æä¸¥é‡å‡åˆ†ï¼ŒåŸºæœ¬æ’é™¤
            debug_info.append(f"å°¾éƒ¨å†…å®¹ç‰¹å¾: -300 (å‘ç°{footer_content_count}ä¸ªå°¾éƒ¨å…³é”®è¯)")
        
        # 3. æ£€æŸ¥ç»“æ„ç‰¹å¾ - footer/headeræ ‡ç­¾å’Œç±»å
        footer_structure_indicators = ['footer', 'foot', 'bottom', 'end', 'copyright', 'links', 'sitemap']
        for indicator in footer_structure_indicators:
            if (indicator in classes or indicator in elem_id or 
                indicator in role or tag_name == 'footer'):
                score -= 250  # æä¸¥é‡å‡åˆ†
                debug_info.append(f"Footerç»“æ„ç‰¹å¾: -250 (å‘ç°'{indicator}')")
        
        # 4. æ£€æŸ¥header/navç»“æ„ç‰¹å¾
        header_structure_indicators = ['header', 'nav', 'navigation', 'menu', 'topbar', 'banner', 'menubar']
        for indicator in header_structure_indicators:
            if (indicator in classes or indicator in elem_id or 
                indicator in role or tag_name in ['header', 'nav','menu']):
                score -= 200  # ä¸¥é‡å‡åˆ†
                debug_info.append(f"Headerç»“æ„ç‰¹å¾: -200 (å‘ç°'{indicator}')")
        
        # 5. æ£€æŸ¥ç¥–å…ˆå…ƒç´ çš„è´Ÿé¢ç‰¹å¾ï¼ˆä½†æƒé‡é™ä½ï¼Œå› ä¸ºç¬¬ä¸€è½®å·²ç»è¿‡æ»¤äº†å¤§éƒ¨åˆ†ï¼‰
        current = container
        depth = 0
        while current is not None and depth < 5:  # å‡å°‘æ£€æŸ¥å±‚çº§
            parent_classes = current.get('class', '').lower()
            parent_id = current.get('id', '').lower()
            parent_tag = current.tag.lower()
            
            # æ£€æŸ¥ç¥–å…ˆçš„footerç‰¹å¾
            for indicator in footer_structure_indicators:
                if (indicator in parent_classes or indicator in parent_id or parent_tag == 'footer'):
                    penalty = max(60 - depth * 10, 15)  # å‡å°‘ç¥–å…ˆç‰¹å¾çš„æƒé‡
                    score -= penalty
                    debug_info.append(f"ç¥–å…ˆFooter: -{penalty} (ç¬¬{depth}å±‚'{indicator}')")
            
            # æ£€æŸ¥ç¥–å…ˆçš„header/navç‰¹å¾
            for indicator in header_structure_indicators:
                if (indicator in parent_classes or indicator in parent_id or parent_tag in ['header', 'nav']):
                    penalty = max(50 - depth * 8, 12)  # å‡å°‘ç¥–å…ˆç‰¹å¾çš„æƒé‡
                    score -= penalty
                    debug_info.append(f"ç¥–å…ˆHeader: -{penalty} (ç¬¬{depth}å±‚'{indicator}')")
            
            current = current.getparent()
            depth += 1
        
        # å¦‚æœå·²ç»æ˜¯ä¸¥é‡è´Ÿåˆ†ï¼Œç›´æ¥è¿”å›ï¼Œä¸éœ€è¦ç»§ç»­è®¡ç®—
        if score < -150:
            return score
        
        # 6. æ­£é¢ç‰¹å¾è¯„åˆ† - ä¸“æ³¨äºå†…å®¹è´¨é‡
        # æ£€æŸ¥æ—¶é—´ç‰¹å¾ï¼ˆå¼ºæ­£é¢ç‰¹å¾ï¼‰
        precise_time_patterns = [
            r'\d{4}-\d{2}-\d{2}',  # YYYY-MM-DD
            r'\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥',  # å®Œæ•´çš„ä¸­æ–‡æ—¥æœŸ
            r'\d{4}/\d{1,2}/\d{1,2}',  # YYYY/MM/DD
            r'å‘å¸ƒæ—¶é—´', r'æ›´æ–°æ—¥æœŸ', r'å‘å¸ƒæ—¥æœŸ', r'åˆ›å»ºæ—¶é—´'
        ]
        
        precise_matches = 0
        for pattern in precise_time_patterns:
            matches = len(re.findall(pattern, text_content))
            precise_matches += matches
        
        if precise_matches > 0:
            time_score = min(precise_matches * 30, 90)  # å¢åŠ æ—¶é—´ç‰¹å¾æƒé‡
            score += time_score
            debug_info.append(f"æ—¶é—´ç‰¹å¾: +{time_score} ({precise_matches}ä¸ªåŒ¹é…)")
        
        # 7. æ£€æŸ¥å†…å®¹é•¿åº¦å’Œè´¨é‡
        items = container.xpath(".//*[self::li or self::tr or self::article or self::div[contains(@class, 'item')]]")
        if items:
            total_length = sum(len(item.text_content().strip()) for item in items)
            avg_length = total_length / len(items) if items else 0
            
            if avg_length > 150:
                score += 40  # å¢åŠ é•¿å†…å®¹çš„æƒé‡
                debug_info.append(f"æ–‡æœ¬é•¿åº¦: +40 (å¹³å‡{avg_length:.1f}å­—ç¬¦)")
            elif avg_length > 80:
                score += 30
                debug_info.append(f"æ–‡æœ¬é•¿åº¦: +30 (å¹³å‡{avg_length:.1f}å­—ç¬¦)")
            elif avg_length > 40:
                score += 20
                debug_info.append(f"æ–‡æœ¬é•¿åº¦: +20 (å¹³å‡{avg_length:.1f}å­—ç¬¦)")
            elif avg_length < 20:  # æ–‡æœ¬å¤ªçŸ­ï¼Œå¯èƒ½æ˜¯å¯¼èˆª
                score -= 20
                debug_info.append(f"æ–‡æœ¬é•¿åº¦: -20 (å¹³å‡{avg_length:.1f}å­—ç¬¦ï¼Œå¤ªçŸ­)")
        
        # 8. æ£€æŸ¥æ­£é¢ç»“æ„ç‰¹å¾
        strong_positive_indicators = ['content', 'main', 'news', 'article', 'data', 'info', 'detail', 'result', 'list']
        positive_score = 0
        for indicator in strong_positive_indicators:
            if indicator in classes or indicator in elem_id:
                positive_score += 25  # å¢åŠ æ­£é¢ç‰¹å¾æƒé‡
                debug_info.append(f"æ­£é¢ç‰¹å¾: +25 ('{indicator}')")
        
        score += min(positive_score, 75)  # é™åˆ¶æ­£é¢ç‰¹å¾çš„æœ€å¤§åŠ åˆ†
        
        # 9. æ£€æŸ¥å†…å®¹å¤šæ ·æ€§ï¼ˆå›¾ç‰‡ã€é“¾æ¥ç­‰ï¼‰
        images = container.xpath(".//img")
        links = container.xpath(".//a[@href]")
        
        if len(images) > 0:
            image_score = min(len(images) * 3, 20)
            score += image_score
            debug_info.append(f"å›¾ç‰‡å†…å®¹: +{image_score} ({len(images)}å¼ å›¾ç‰‡)")
        
        if len(links) > 5:  # æœ‰è¶³å¤Ÿçš„é“¾æ¥è¯´æ˜æ˜¯å†…å®¹åŒºåŸŸ
            link_score = min(len(links) * 2, 30)
            score += link_score
            debug_info.append(f"é“¾æ¥å†…å®¹: +{link_score} ({len(links)}ä¸ªé“¾æ¥)")
        
        # 10. æœ€åæ£€æŸ¥ï¼šé¿å…å¯¼èˆªç±»å†…å®¹ï¼ˆä½†æƒé‡é™ä½ï¼Œå› ä¸ºç¬¬ä¸€è½®å·²ç»è¿‡æ»¤äº†å¤§éƒ¨åˆ†ï¼‰
        if items and len(items) > 2:
            # åªæ£€æŸ¥æ˜æ˜¾çš„å¯¼èˆªè¯æ±‡ï¼Œå‡å°‘è¯¯åˆ¤
            strong_nav_words = [
                'ç™»å½•', 'æ³¨å†Œ', 'é¦–é¡µ', 'ä¸»é¡µ', 'æ— éšœç¢', 'æ”¿åŠ¡', 'åŠäº‹', 'äº’åŠ¨', 
                'èµ°è¿›', 'ç§»åŠ¨ç‰ˆ', 'æ‰‹æœºç‰ˆ', 'å¯¼èˆª', 'èœå•', 'æœç´¢', 'å¸‚æ”¿åºœ',
                'login', 'register', 'home', 'menu', 'search', 'nav'
            ]
            nav_word_count = 0
            
            for item in items[:8]:  # å‡å°‘æ£€æŸ¥çš„é¡¹ç›®æ•°
                item_text = item.text_content().strip().lower()
                for nav_word in strong_nav_words:
                    if nav_word in item_text:
                        nav_word_count += 1
                        break
            
            checked_items = min(len(items), 8)
            if nav_word_count > checked_items * 0.4:  # æé«˜é˜ˆå€¼ï¼Œå‡å°‘è¯¯åˆ¤
                nav_penalty = 30  # å‡å°‘å¯¼èˆªè¯æ±‡çš„å‡åˆ†
                score -= nav_penalty
                debug_info.append(f"å¯¼èˆªè¯æ±‡: -{nav_penalty} ({nav_word_count}/{checked_items}ä¸ª)")
        
        # è¾“å‡ºè°ƒè¯•ä¿¡æ¯
        container_info = f"æ ‡ç­¾:{tag_name}, ç±»å:{classes[:30]}{'...' if len(classes) > 30 else ''}"
        if elem_id:
            container_info += f", ID:{elem_id[:20]}{'...' if len(elem_id) > 20 else ''}"
        
        logger.info(f"å®¹å™¨è¯„åˆ†: {score} - {container_info}")
        for info in debug_info:  # æ˜¾ç¤ºæ›´å¤šè°ƒè¯•ä¿¡æ¯
            logger.info(f"  {info}")
        
        return score
    
    # ç¬¬ä¸€å±‚ï¼šæ‰¾åˆ°æ‰€æœ‰å¯èƒ½çš„åˆ—è¡¨é¡¹
    all_items = []
    for selector in list_selectors:
        items = page_tree.xpath(selector)
        all_items.extend(items)
    
    if not all_items:
        return None
    
    # æŒ‰ç…§çˆ¶å…ƒç´ åˆ†ç»„ï¼Œæ‰¾åˆ°åŒ…å«åˆ—è¡¨é¡¹çš„çˆ¶å…ƒç´ 
    parent_counts = {}
    for item in all_items:
        parent = item.getparent()
        if parent is not None:
            if parent not in parent_counts:
                parent_counts[parent] = 0
            parent_counts[parent] += 1
    
    if not parent_counts:
        return None
    
    # ç­›é€‰å€™é€‰å®¹å™¨ï¼šè‡³å°‘åŒ…å«3ä¸ªåˆ—è¡¨é¡¹
    candidate_containers = [(parent, count) for parent, count in parent_counts.items() if count >= 3]
    
    # å¦‚æœæ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„å®¹å™¨ï¼Œé™ä½é—¨æ§›åˆ°2ä¸ªåˆ—è¡¨é¡¹
    if not candidate_containers:
        candidate_containers = [(parent, count) for parent, count in parent_counts.items() if count >= 2]
    
    # å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œè¿”å›åŒ…å«æœ€å¤šåˆ—è¡¨é¡¹çš„å®¹å™¨
    if not candidate_containers:
        return max(parent_counts.items(), key=lambda x: x[1])[0]
    
    # å¯¹å€™é€‰å®¹å™¨è¿›è¡Œè¯„åˆ†å¹¶æ’åº
    scored_containers = []
    for container, count in candidate_containers:
        score = calculate_container_score(container)
        
        # é¢å¤–æ£€æŸ¥ï¼šå¦‚æœå®¹å™¨åœ¨footeråŒºåŸŸï¼Œä¸¥é‡å‡åˆ†
        is_footer, footer_msg = is_in_footer_area(container)
        ancestry_penalty = 0
        
        if is_footer:
            ancestry_penalty += 50  # footeråŒºåŸŸä¸¥é‡å‡åˆ†
        
        # æ£€æŸ¥å…¶ä»–è´Ÿé¢ç¥–å…ˆç‰¹å¾ - ä½†æƒé‡é™ä½ï¼Œå› ä¸ºç¬¬ä¸€è½®å·²ç»è¿‡æ»¤äº†å¤§éƒ¨åˆ†
        def check_negative_ancestry(element):
            """æ£€æŸ¥å…ƒç´ åŠå…¶ç¥–å…ˆçš„è´Ÿé¢ç‰¹å¾"""
            penalty = 0
            current = element
            depth = 0
            while current is not None and depth < 4:  # å‡å°‘æ£€æŸ¥å±‚çº§
                classes = current.get('class', '').lower()
                elem_id = current.get('id', '').lower()
                text_content = current.text_content().lower()
                
                # æ£€æŸ¥ç»“æ„ç‰¹å¾
                negative_keywords = ['nav', 'menu', 'sidebar', 'header', 'topbar', 'navigation', 'head']
                for keyword in negative_keywords:
                    if keyword in classes or keyword in elem_id:
                        penalty += 20  # å‡å°‘ç¥–å…ˆç‰¹å¾çš„æƒé‡
                
                # æ£€æŸ¥å†…å®¹ç‰¹å¾ï¼ˆåªåœ¨å‰2å±‚æ£€æŸ¥ï¼‰
                if depth < 2:
                    footer_content_keywords = ['ç½‘ç«™è¯´æ˜', 'ç½‘ç«™æ ‡è¯†ç ', 'ç‰ˆæƒæ‰€æœ‰', 'å¤‡æ¡ˆå·']
                    header_content_keywords = ['ç™»å½•', 'æ³¨å†Œ', 'é¦–é¡µ', 'æ— éšœç¢']
                    
                    content_penalty = 0
                    for keyword in footer_content_keywords + header_content_keywords:
                        if keyword in text_content:
                            content_penalty += 15
                    
                    if content_penalty > 30:  # å¦‚æœåŒ…å«å¤šä¸ªå…³é”®è¯
                        penalty += content_penalty
                
                current = current.getparent()
                depth += 1
            return penalty
        
        ancestry_penalty += check_negative_ancestry(container)
        #æœ€ç»ˆåˆ†æ•°
        final_score = score - ancestry_penalty
        
        scored_containers.append((container, final_score, count))
    
    # æŒ‰åˆ†æ•°æ’åºï¼Œä½†ä¼˜å…ˆè€ƒè™‘åˆ†æ•°è€Œä¸æ˜¯æ•°é‡
    scored_containers.sort(key=lambda x: x[1], reverse=True)
    
    # ä¸¥æ ¼è¿‡æ»¤è´Ÿåˆ†å®¹å™¨ - æé«˜é˜ˆå€¼ï¼Œæ›´ä¸¥æ ¼åœ°æ’é™¤é¦–éƒ¨å°¾éƒ¨
    positive_scored = [sc for sc in scored_containers if sc[1] > 0]  # åªæ¥å—æ­£åˆ†å®¹å™¨
    
    if positive_scored:
        # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„æ­£åˆ†å®¹å™¨
        best_container = positive_scored[0][0]
        max_items = parent_counts[best_container]
    else:
        # å¦‚æœæ²¡æœ‰æ­£åˆ†å®¹å™¨ï¼Œå°è¯•ç¨å¾®å®½æ¾çš„é˜ˆå€¼
        moderate_scored = [sc for sc in scored_containers if sc[1] > -50]
        
        if moderate_scored:
            best_container = moderate_scored[0][0]
            max_items = parent_counts[best_container]
        else:
            # æœ€åæ‰‹æ®µï¼šé€‰æ‹©å¾—åˆ†æœ€é«˜çš„ï¼ˆä½†å¾ˆå¯èƒ½ä¸ç†æƒ³ï¼‰
            best_container = scored_containers[0][0]
            max_items = parent_counts[best_container]
    
    # é€å±‚å‘ä¸Šæœç´¢ä¼˜åŒ–å®¹å™¨
    current_container = best_container
    while True:
        parent = current_container.getparent()
        if parent is None or parent.tag == 'html':
            break
        
        # æ£€æŸ¥çˆ¶çº§å…ƒç´ æ˜¯å¦åŒ…å«footerç­‰è´Ÿé¢ç‰¹å¾ - æ›´ä¸¥æ ¼çš„æ£€æŸ¥
        def has_negative_ancestor(element):
            """æ£€æŸ¥å…ƒç´ çš„ç¥–å…ˆæ˜¯å¦åŒ…å«è´Ÿé¢ç‰¹å¾ - åŒ…æ‹¬å†…å®¹ç‰¹å¾"""
            current = element
            depth = 0
            while current is not None and depth < 3:  # æ£€æŸ¥3å±‚ç¥–å…ˆ
                parent_classes = current.get('class', '').lower()
                parent_id = current.get('id', '').lower()
                parent_tag = current.tag.lower()
                parent_text = current.text_content().lower()
                
                # æ£€æŸ¥ç»“æ„è´Ÿé¢å…³é”®è¯
                structure_negative = ['footer', 'nav', 'menu', 'sidebar', 'header', 'topbar', 'navigation', 'foot', 'head']
                for keyword in structure_negative:
                    if (keyword in parent_classes or keyword in parent_id or parent_tag in ['footer', 'header', 'nav']):
                        return True
                
                # æ£€æŸ¥å†…å®¹è´Ÿé¢ç‰¹å¾ï¼ˆåªåœ¨å‰2å±‚æ£€æŸ¥ï¼Œé¿å…è¿‡åº¦æ£€æŸ¥ï¼‰
                if depth < 2:
                    # é¦–éƒ¨å†…å®¹ç‰¹å¾
                    header_content = ['ç™»å½•', 'æ³¨å†Œ', 'é¦–é¡µ', 'ä¸»é¡µ', 'æ— éšœç¢', 'æ”¿åŠ¡', 'åŠäº‹', 'äº’åŠ¨', 'èµ°è¿›']
                    header_count = sum(1 for word in header_content if word in parent_text)
                    
                    # å°¾éƒ¨å†…å®¹ç‰¹å¾
                    footer_content = ['ç½‘ç«™è¯´æ˜', 'ç½‘ç«™æ ‡è¯†ç ', 'ç‰ˆæƒæ‰€æœ‰', 'å¤‡æ¡ˆå·', 'icp', 'ä¸»åŠå•ä½', 'æ‰¿åŠå•ä½']
                    footer_count = sum(1 for word in footer_content if word in parent_text)
                    
                    # å¦‚æœåŒ…å«å¤šä¸ªé¦–éƒ¨æˆ–å°¾éƒ¨å…³é”®è¯ï¼Œè®¤ä¸ºæ˜¯è´Ÿé¢ç¥–å…ˆ
                    if header_count >= 2:
                        return True
                    if footer_count >= 2:
                        return True
                
                current = current.getparent()
                depth += 1
            return False
        
        # å¦‚æœçˆ¶å…ƒç´ æˆ–å…¶ç¥–å…ˆåŒ…å«è´Ÿé¢ç‰¹å¾ï¼Œåœæ­¢å‘ä¸Šæœç´¢
        if has_negative_ancestor(parent):
            logger.info("çˆ¶çº§åŒ…å«è´Ÿé¢ç‰¹å¾ï¼Œåœæ­¢å‘ä¸Šæœç´¢")
            break
            
        # è®¡ç®—çˆ¶å…ƒç´ ä¸­çš„åˆ—è¡¨é¡¹æ•°é‡
        parent_items = count_list_items(parent)
        
        # æ£€æŸ¥çˆ¶å…ƒç´ æ˜¯å¦æ›´é€‚åˆä½œä¸ºå®¹å™¨
        parent_score = calculate_container_score(parent)
        current_score = calculate_container_score(current_container)
        
        logger.info(f"æ¯”è¾ƒå¾—åˆ†: å½“å‰={current_score}, çˆ¶çº§={parent_score}")
        logger.info(f"é¡¹ç›®æ•°é‡: å½“å‰={max_items}, çˆ¶çº§={parent_items}")
        
        should_upgrade = False
        
        # é¦–å…ˆæ£€æŸ¥çˆ¶çº§æ˜¯å¦æœ‰ä¸¥é‡çš„è´Ÿé¢ç‰¹å¾
        if parent_score < -50:
            logger.info(f"çˆ¶çº§å¾—åˆ†è¿‡ä½({parent_score})ï¼Œè·³è¿‡å‡çº§")
        else:
            # æ¡ä»¶1ï¼šçˆ¶çº§å¾—åˆ†æ˜æ˜¾æ›´é«˜ä¸”ä¸ºæ­£åˆ†
            if parent_score > current_score + 15 and parent_score > 10:
                should_upgrade = True
                logger.info("çˆ¶çº§å¾—åˆ†æ˜æ˜¾æ›´é«˜ä¸”ä¸ºæ­£åˆ†ï¼Œå‡çº§")
            
            # æ¡ä»¶2ï¼šçˆ¶çº§å¾—åˆ†ç›¸è¿‘ä¸”ä¸ºæ­£åˆ†ï¼ŒåŒ…å«åˆç†æ•°é‡çš„é¡¹ç›®
            elif (parent_score >= current_score - 3 and 
                  parent_score > 5 and  # è¦æ±‚çˆ¶çº§å¿…é¡»æ˜¯æ­£åˆ†
                  parent_items <= max_items * 2 and  # æ›´ä¸¥æ ¼çš„é¡¹ç›®æ•°é‡é™åˆ¶
                  parent_items >= max_items):
                should_upgrade = True
                logger.info("çˆ¶çº§å¾—åˆ†ç›¸è¿‘ä¸”ä¸ºæ­£åˆ†ï¼Œå‡çº§")
            
            # æ¡ä»¶3ï¼šå½“å‰å®¹å™¨é¡¹ç›®å¤ªå°‘ï¼Œçˆ¶çº§æœ‰åˆç†æ•°é‡ä¸”å¾—åˆ†ä¸é”™
            elif (max_items < 4 and 
                  parent_items >= max_items and 
                  parent_items <= 15 and 
                  parent_score > 0):  # è¦æ±‚çˆ¶çº§å¿…é¡»æ˜¯æ­£åˆ†
                should_upgrade = True
                logger.info("å½“å‰å®¹å™¨é¡¹ç›®å¤ªå°‘ï¼Œå‡çº§åˆ°æ­£åˆ†çˆ¶çº§")
        
        if should_upgrade:
            current_container = parent
            max_items = parent_items
            logger.info("å‡çº§åˆ°çˆ¶çº§å®¹å™¨")
        else:
            logger.info("ä¿æŒå½“å‰å®¹å™¨")
            break
        
        # å®‰å…¨æ£€æŸ¥ï¼šå¦‚æœçˆ¶çº§é¡¹ç›®æ•°é‡è¿‡å¤šï¼Œåœæ­¢
        if parent_items > 50:
            logger.info(f"çˆ¶çº§é¡¹ç›®æ•°é‡è¿‡å¤š({parent_items})ï¼Œåœæ­¢å‘ä¸Šæœç´¢")
            break
    
    # æœ€ç»ˆéªŒè¯ï¼šç¡®ä¿é€‰æ‹©çš„å®¹å™¨åŒ…å«è¶³å¤Ÿçš„åˆ—è¡¨é¡¹ä¸”ä¸æ˜¯é¦–éƒ¨å°¾éƒ¨
    final_items = count_list_items(current_container)
    final_score = calculate_container_score(current_container)
    logger.info(f"æœ€ç»ˆå®¹å™¨åŒ…å« {final_items} ä¸ªåˆ—è¡¨é¡¹ï¼Œå¾—åˆ†: {final_score}")
    
    # å¦‚æœæœ€ç»ˆå®¹å™¨é¡¹ç›®å¤ªå°‘ä¸”å¾—åˆ†ä¸å¥½ï¼Œå°è¯•å‘ä¸Šæ‰¾ä¸€å±‚
    if final_items < 4 or final_score < -10:
        parent = current_container.getparent()
        if parent is not None and parent.tag != 'html':
            parent_items = count_list_items(parent)
            parent_score = calculate_container_score(parent)
            
            # æ›´ä¸¥æ ¼çš„æ¡ä»¶ï¼šçˆ¶çº§å¿…é¡»æœ‰æ›´å¤šé¡¹ç›®ä¸”å¾—åˆ†ä¸ºæ­£åˆ†
            if (parent_items > final_items and 
                parent_score > 0 and  # è¦æ±‚æ­£åˆ†
                parent_items <= 30):  # é¿å…é€‰æ‹©è¿‡å¤§çš„å®¹å™¨
                logger.info(f"æœ€ç»ˆè°ƒæ•´ï¼šé€‰æ‹©æ­£åˆ†çˆ¶çº§å®¹å™¨ (é¡¹ç›®æ•°: {parent_items}, å¾—åˆ†: {parent_score})")
                current_container = parent
            else:
                logger.info(f"çˆ¶çº§ä¸ç¬¦åˆæ¡ä»¶ (é¡¹ç›®æ•°: {parent_items}, å¾—åˆ†: {parent_score})ï¼Œä¿æŒå½“å‰é€‰æ‹©")
    
    return current_container
def generate_xpath(element):
    if not element:
        return None

    tag = element.tag

    # 1. ä¼˜å…ˆä½¿ç”¨IDï¼ˆå¦‚æœå­˜åœ¨ä¸”ä¸æ˜¯å¹²æ‰°ç‰¹å¾ï¼‰
    elem_id = element.get('id')
    if elem_id and not is_interference_identifier(elem_id):
        return f"//{tag}[@id='{elem_id}']"

    # 2. ä½¿ç”¨ç±»åï¼ˆè¿‡æ»¤å¹²æ‰°ç±»åï¼‰
    # classes = element.get('class')
    # if classes:
    #     class_list = [cls.strip() for cls in classes.split() if cls.strip()]
    #     # è¿‡æ»¤æ‰å¹²æ‰°ç±»å
    #     clean_classes = [cls for cls in class_list if not is_interference_identifier(cls)]
    #     if clean_classes:
    #         # é€‰æ‹©æœ€é•¿çš„å¹²å‡€ç±»å
    #         longest_class = max(clean_classes, key=len)
    #         return f"//{tag}[contains(concat(' ', normalize-space(@class), ' '), ' {longest_class} ')]"
    classes = element.get('class')
    if classes:
        # ä½¿ç”¨å®Œæ•´çš„classå€¼ï¼Œä¸è¿›è¡Œè¿‡æ»¤å¤„ç†
        return f"//{tag}[@class='{classes}']"

    # 3. ä½¿ç”¨å…¶ä»–å±æ€§ï¼ˆå¦‚ aria-label ç­‰ï¼‰
    for attr in ['aria-label', 'role', 'data-testid', 'data-role']:
        attr_value = element.get(attr)
        if attr_value and not is_interference_identifier(attr_value):
            return f"//{tag}[@{attr}='{attr_value}']"

    # 4. å°è¯•æ‰¾åˆ°æœ€è¿‘çš„æœ‰å¹²å‡€æ ‡è¯†ç¬¦çš„ç¥–å…ˆ
    def find_closest_clean_identifier(el):
        parent = el.getparent()
        while parent is not None and parent.tag != 'html':
            # æ£€æŸ¥ID
            parent_id = parent.get('id')
            if parent_id and not is_interference_identifier(parent_id):
                return parent
            
            # æ£€æŸ¥ç±»å
            parent_classes = parent.get('class')
            if parent_classes:
                parent_class_list = [cls.strip() for cls in parent_classes.split() if cls.strip()]
                clean_parent_classes = [cls for cls in parent_class_list if not is_interference_identifier(cls)]
                if clean_parent_classes:
                    return parent
            parent = parent.getparent()
        return None

    ancestor = find_closest_clean_identifier(element)
    if ancestor is not None:
        # ç”Ÿæˆç¥–å…ˆçš„ XPath
        ancestor_xpath = generate_xpath(ancestor)
        if ancestor_xpath:
            # ç”Ÿæˆä»ç¥–å…ˆåˆ°å½“å‰å…ƒç´ çš„ç›¸å¯¹è·¯å¾„
            def generate_relative_path(ancestor_el, target_el):
                path = []
                current = target_el
                while current is not None and current != ancestor_el:
                    index = 1
                    sibling = current.getprevious()
                    while sibling is not None:
                        if sibling.tag == current.tag:
                            index += 1
                        sibling = sibling.getprevious()
                    path.insert(0, f"{current.tag}[{index}]")
                    current = current.getparent()
                return '/' + '/'.join(path)

            relative_path = generate_relative_path(ancestor, element)
            return f"{ancestor_xpath}{relative_path}"

    # 5. åŸºäºä½ç½®çš„ XPathï¼ˆæœ€åæ‰‹æ®µï¼‰
    path = []
    current = element
    while current is not None and current.tag != 'html':
        index = 1
        sibling = current.getprevious()
        while sibling is not None:
            if sibling.tag == current.tag:
                index += 1
            sibling = sibling.getprevious()
        path.insert(0, f"{current.tag}[{index}]")
        current = current.getparent()

    return '/' + '/'.join(path)

def is_interference_identifier(identifier):
    """åˆ¤æ–­æ ‡è¯†ç¬¦æ˜¯å¦åŒ…å«å¹²æ‰°ç‰¹å¾"""
    if not identifier:
        return False
    
    identifier_lower = identifier.lower()
    
    # å¹²æ‰°å…³é”®è¯
    interference_keywords = [
        'header', 'footer', 'nav', 'navigation', 'menu', 'menubar',
        'topbar', 'bottom', 'sidebar', 'aside', 'banner', 'ad'
    ]
    
    for keyword in interference_keywords:
        if keyword in identifier_lower:
            return True
    
    return False

# ç§»é™¤äº†éªŒè¯å‡½æ•°ï¼Œç°åœ¨åªéœ€è¦æ ¸å¿ƒçš„HTMLå¤„ç†


# ç§»é™¤äº†æ‰€æœ‰æµè§ˆå™¨å’Œæ–‡ä»¶å¤„ç†ç›¸å…³çš„å‡½æ•°


# FastAPIè·¯ç”±
@app.get("/")
async def root():
    """æ ¹è·¯å¾„ï¼Œè¿”å›APIä¿¡æ¯"""
    return {
        "message": "HTML to Markdown Content Extractor API",
        "version": "2.0.0",
        "endpoints": {
            "/extract": "POST - Extract main content from HTML and convert to Markdown",
            "/health": "GET - Health check"
        }
    }

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat()
    }

@app.post("/extract", response_model=MarkdownOutput)
async def extract_html_to_markdown(input_data: HTMLInput):
    """
    ä»HTMLå†…å®¹ä¸­æå–æ­£æ–‡å¹¶è½¬æ¢ä¸ºMarkdownæ ¼å¼
    
    Args:
        input_data: åŒ…å«HTMLå†…å®¹çš„è¾“å…¥æ•°æ®
        
    Returns:
        MarkdownOutput: åŒ…å«Markdownå†…å®¹ã€XPathå’ŒçŠ¶æ€çš„å“åº”
    """
    try:
        if not input_data.html_content.strip():
            raise HTTPException(status_code=400, detail="HTMLå†…å®¹ä¸èƒ½ä¸ºç©º")
        
        logger.info("å¼€å§‹å¤„ç†HTMLå†…å®¹æå–")
        
        # æå–å†…å®¹å¹¶è½¬æ¢ä¸ºMarkdown
        result = extract_content_to_markdown(input_data.html_content)
        
        if result['status'] == 'failed':
            raise HTTPException(status_code=422, detail="æ— æ³•ä»HTMLä¸­æå–æœ‰æ•ˆå†…å®¹")
        
        return MarkdownOutput(
            markdown_content=result['markdown_content'],
            xpath=result['xpath'],
            status=result['status']
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}")

import os
import glob

# å¯åŠ¨æœåŠ¡å™¨çš„å‡½æ•°
def start_server(host: str = "0.0.0.0", port: int = 8000):
    """å¯åŠ¨FastAPIæœåŠ¡å™¨"""
    uvicorn.run(app, host=host, port=port)

if __name__ == "__main__":
    # å¯ä»¥é€‰æ‹©è¿è¡ŒåŸæœ‰çš„æ–‡ä»¶å¤„ç†é€»è¾‘æˆ–å¯åŠ¨APIæœåŠ¡å™¨
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "api":
        # å¯åŠ¨APIæœåŠ¡å™¨
        print("å¯åŠ¨HTML to Markdown APIæœåŠ¡å™¨...")
        print("APIæ–‡æ¡£: http://localhost:8000/docs")
        print("å¥åº·æ£€æŸ¥: http://localhost:8000/health")
        start_server()
    else:
        # åŸæœ‰çš„æ–‡ä»¶å¤„ç†é€»è¾‘ï¼ˆä¿ç•™å‘åå…¼å®¹ï¼‰
        try:
            input_file = "test.yml"    # è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_file = "testout.yml"  # è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
            process_yml_file(input_file, output_file)

            # input_folder = "waitprocess"
            # output_folder = "processed"  
            
            # if not os.path.exists(output_folder):
            #     os.makedirs(output_folder)
            
            # files = glob.glob(os.path.join(input_folder, "*.yml"))
            
            # for input_file in files:
            #     base_name = os.path.basename(input_file)  
            #     output_file = os.path.join(output_folder, base_name)
            #     process_yml_file(input_file, output_file)
        finally:
            driver_pool.close_all()


# version1.0 

# ä¸€ä¸ªé¡µé¢ä¸­ï¼Œå­˜åœ¨kä¸ªåˆ—è¡¨ï¼Œå‡å®šk=3ï¼Œæœ‰ä¸‰ä¸ªåˆ—è¡¨ï¼Œåˆ—è¡¨1ä¸ºå¯¼èˆªæ ï¼Œé‡Œé¢æœ‰8ä¸ªåˆ—è¡¨é¡¹ï¼Œåˆ—è¡¨2ä¸ºä¾§è¾¹æ ï¼Œé‡Œé¢æœ‰5ä¸ªåˆ—è¡¨é¡¹ï¼Œåˆ—è¡¨3æ˜¯äº‹é¡¹åˆ—è¡¨ï¼Œé‡Œé¢æœ‰7ä¸ªåˆ—è¡¨é¡¹ï¼Œ
# æ­¤æ—¶ï¼Œæˆ‘çš„ä»£ç ä¼šæŠŠåˆ—è¡¨1ä½œä¸ºç›®æ ‡è·å–ï¼Œä½†å®é™…æƒ…å†µåº”è¯¥æ˜¯åˆ—è¡¨3æ‰æ˜¯æ­£ç¡®çš„ï¼Œè¿™æ€ä¹ˆåŠå‘¢ï¼Œ
# ç›®å‰å¯¹äºç›®æ ‡åˆ—è¡¨3ï¼Œå¯èƒ½å­˜åœ¨ä»¥ä¸‹ç‰¹ç‚¹ï¼šé‡Œé¢å¾€å¾€å­˜åœ¨æ—¶é—´å­—ç¬¦ä¸²ï¼Œå¹¶ä¸”æœ‰äº›é¡µé¢ä¸­çš„æ–‡å­—çš„é•¿åº¦æ˜¯å¤§äºåˆ—è¡¨1å’Œåˆ—è¡¨2çš„ã€‚
# é™¤æ­¤ä¹‹å¤–ï¼Œå¯¹äºåˆ—è¡¨1ï¼Œä¹Ÿæœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼šå½“æˆ‘ä»¬è¯¯è·å–è¿™ä¸ªåˆ—è¡¨1çš„æ—¶å€™ï¼Œä¼šå»å¤„ç†ç»„è£…ä»–çš„xpathï¼Œè¿™ä¸ªxpathé‡Œé¢å¾€å¾€æ˜¯å­˜åœ¨navä¸‰ä¸ªå­—æ¯çš„ï¼Œ
# åœ¨æˆ‘çš„è§‚å¯Ÿä¸‹ï¼Œå¤§éƒ¨åˆ†æƒ…å†µä¸­ï¼Œåªè¦xpathé‡Œé¢åŒ…å«navï¼Œé‚£å°±å¾ˆå¤§å¯èƒ½è¯´æ˜è·å–å¤±è´¥äº†ï¼Œæ²¡æœ‰è·å–åˆ°åˆ—è¡¨3ï¼Œè€Œæ˜¯è·å–åˆ°äº†åˆ—è¡¨1

# å¯¹äºjsé¡µé¢ï¼Œnameä¸­åç§°ä¸€å®šè¦å‡†ç¡®ï¼Œå¹¶ä¸”ï¼nameè¦å°½é‡è¦å°‘ä¸€ç‚¹ï¼Œæ¯”å¦‚â€œæ³•å®šä¸»åŠ¨å…¬å¼€å†…å®¹â€ï¼Œè¿™ä¸ªå°±å†™â€œæ³•å®šâ€å³å¯ï¼Œè¿™ä¿©å­—æœ‰ä»£è¡¨æ€§ï¼Œä¸èƒ½å†™â€œå†…å®¹â€è¿™ä¿©å­—ï¼Œæ²¡æœ‰ä»»ä½•çš„ä»£è¡¨æ€§


# version2.0
# 2025.8.22
# ä¿®æ”¹éƒ¨åˆ†ç®—æ³•çš„é€»è¾‘ï¼Œå¯ä»¥æå–æ­£æ–‡æ‰€åœ¨å®¹å™¨ï¼Œè€Œä¸æ˜¯v1.0ä¸­æå–åˆ—è¡¨ï¼Œç›®å‰ç®—æ³•ç”¨äºå®šä½é¡µé¢çš„ä¸»ä½“å†…å®¹ï¼Œé€šè¿‡ä¸æ–­çš„å»æ’é™¤å¤´éƒ¨å¯¼èˆªå’Œåº•éƒ¨footeræ¥é€æ¸çš„å®šä½ä¸»ä½“ã€‚ä½†æ˜¯ï¼Œå¯¹äºé¡µé¢ä¸­å†…å®¹æ˜¯ä¸€å¤§ä¸²çš„æ–‡å­—ï¼Œæˆ–è€…æ˜¯å›¾ç‰‡ï¼Œè¿™ç§æƒ…å†µä¸‹å¯†åº¦ç®—æ³•å°†ä¼šå¤±æ•ˆï¼Œæˆ‘ä»¬éœ€è¦å°½å¯èƒ½çš„æ’é™¤ä¸»HTMLä¸­headå’Œfooterï¼ˆå°±æ˜¯é¡µé¢çš„å¯¼èˆªæ å’Œåº•éƒ¨æ ï¼Œè¿™ä¸¤ä¸ªé‡Œé¢å¯èƒ½å­˜åœ¨å¤§é‡çš„åˆ—è¡¨æˆ–è€…ä¸€å¤§ä¸²çš„æ–‡å­—ï¼‰
# è·å–åˆ°çš„æ¬¡HTMLå³ä¸ºæ’é™¤äº†å¹²æ‰°é¡¹çš„HTMLå†…å®¹ï¼Œæˆ‘ä»¬éœ€è¦çš„containerå¯èƒ½å°±å­˜åœ¨äºæ­¤ï¼Œå¯¹äºè¿™ä¸ªæ¬¡çº§HTMLï¼Œæˆ‘ä»¬éœ€è¦å†ä¸€æ¬¡çš„è¿›è¡Œè¿‡æ»¤ï¼Œæ’é™¤é‡Œé¢çš„headerå’Œfooterï¼Œç„¶åé€æ­¥ç¼©å°ï¼Œä½†æ˜¯ä¸è¦ç²¾ç¡®ï¼Œå› ä¸ºè¿‡äºç²¾ç¡®çš„è·å–å®¹å™¨ä¼šå¯¼è‡´å‡ºç°ç–æ¼ã€‚

# å¯¹äºç®—æ³•çš„è¿›ä¸€æ­¥ä¿®æ”¹ï¼Œéœ€è¦åˆ¤æ–­å‡ºä¸€ä¸ªåˆç†çš„æƒé‡ï¼Œå³æ‰£åˆ†æ ‡å‡†ã€‚é¦–å…ˆï¼ä¸€å®šæ˜¯æ‰£åˆ†çš„å±…å¤šï¼ŒåŠ åˆ†çš„å°‘ï¼Œå¯¹äºå¯èƒ½æ˜¯åº•éƒ¨æˆ–è€…é¦–éƒ¨çš„å†…å®¹ï¼Œè¦å¤§é‡çš„å‡åˆ†ï¼Œåº”è¯¥ç®—æ³•çš„ä¸»è¦æ€è·¯å°±æ˜¯æ’é™¤å¹²æ‰°é¡¹ï¼
